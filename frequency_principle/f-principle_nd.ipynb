{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List\n",
    "import argparse\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import re\n",
    "from torch.utils.data import DataLoader, Dataset, Subset, TensorDataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Default configuration parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description='PyTorch Training for Frequency Principle')\n",
    "\n",
    "\n",
    "parser.add_argument('--lr', default=1e-3, type=float, help='learning rate')\n",
    "parser.add_argument('--optimizer', default='nesterov',\n",
    "                    help='optimizer: sgd | adam | nesterov')\n",
    "parser.add_argument('--epochs', default=100, type=int,\n",
    "                    metavar='N', help='number of total epochs to run')\n",
    "parser.add_argument('--training_batch_size',   default=50, type=int,\n",
    "                    help='the batch size for model (default: 1000)')\n",
    "parser.add_argument('--training_size',   default=5000, type=int,\n",
    "                    help='the training size for model (default: 1000)')\n",
    "parser.add_argument('--test_batch_size',   default=50, type=int,\n",
    "                    help='the test size for model (default: 10000)')\n",
    "parser.add_argument('--act_func_name', default='ReLU',\n",
    "                    help='activation function')\n",
    "parser.add_argument('--in_channel',   default=3, type=int,\n",
    "                    help='the input channel for model (default: 3)')\n",
    "parser.add_argument('--num_classes',   default=10, type=int,\n",
    "                    help='the output dimension for model (default: 10)')\n",
    "parser.add_argument('--device',   default='cuda', type=str,\n",
    "                    help='device used to train (cpu or cuda)')\n",
    "parser.add_argument('--plot_epoch',   default=1, type=int,\n",
    "                    help='step size of plotting interval (default: 1000)')\n",
    "parser.add_argument('--ini_path', type=str,\n",
    "                    default='')\n",
    "parser.add_argument('--start_filter',   default=2, type=float,\n",
    "                    help='the start point of the filter (default: 2)')\n",
    "parser.add_argument('--end_filter',   default=100, type=float,\n",
    "                    help='the end point of the filter (default: 100)')\n",
    "parser.add_argument('--num_filter',   default=20, type=int,\n",
    "                    help='the point number of the filter (default: 20)')\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   The storage path of the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save path: 20230614154423543332\n"
     ]
    }
   ],
   "source": [
    "def mkdirs(fn):\n",
    "    \"\"\"\n",
    "    Create directories if they don't exist.\n",
    "\n",
    "    Args:\n",
    "    fn: The directory path to create.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.isdir(fn):\n",
    "        os.makedirs(fn)\n",
    "\n",
    "\n",
    "def create_save_dir(path_ini):\n",
    "    \"\"\"\n",
    "    Create a new directory with the current date and time as its name and return the path of the new directory.\n",
    "\n",
    "    Args:\n",
    "    path_ini: The initial path to create the new directory.\n",
    "\n",
    "    Return:\n",
    "    The path of the new directory.\n",
    "    \"\"\"\n",
    "    subFolderName = re.sub(r'[^0-9]', '', str(datetime.datetime.now()))\n",
    "    path = os.path.join(path_ini, subFolderName)\n",
    "    mkdirs(path)\n",
    "    mkdirs(os.path.join(path, 'output'))\n",
    "    return path\n",
    "\n",
    "\n",
    "args.path = create_save_dir(args.ini_path)\n",
    "print('save path: %s' % (args.path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of dataloader.\n",
    "\n",
    "A dataloader is a utility in PyTorch that helps to load and preprocess data for machine learning models. It is used to efficiently load large datasets and feed them to the model in batches during training or inference. \n",
    "\n",
    "The `load_data` function defines a dataloader for the CIFAR10 dataset. The function loads the CIFAR10 dataset using the `datasets.CIFAR10` class and applies the `transform` object to the data. It creates a `Subset` object from the training dataset, which selects a subset of the data based on the `training_size` argument. \n",
    "\n",
    "The `DataLoader` class is then used to create dataloaders for the training and test datasets. The `train_loader` loads the training data in batches of size `training_batch_size`, while the `test_loader` loads the test data in batches of size `test_batch_size`. The `num_workers` argument specifies the number of subprocesses to use for data loading, while the `shuffle` argument specifies whether to shuffle the data before each epoch. \n",
    "\n",
    "\n",
    "This will return two dataloaders: `train_loader` and `test_loader`, which can be used to iterate over the training and test data in batches during training or inference.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_data(training_size, training_batch_size, test_batch_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "        #                     std=[x/255.0 for x in [63.0, 62.1, 66.7]]),\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root=\"./\",\n",
    "                                    train=True,\n",
    "                                    transform=transform,\n",
    "                                    download=True\n",
    "                                    )\n",
    "\n",
    "    test_dataset = datasets.CIFAR10(root=\"./\",\n",
    "                                    train=False,\n",
    "                                    transform=transform,\n",
    "                                    download=True)\n",
    "    \n",
    "\n",
    "    train_dataset=Subset(train_dataset,range(training_size))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "    train_dataset, batch_size=training_batch_size,  num_workers=2, shuffle=False,drop_last=True, pin_memory=True)\n",
    "\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                                 batch_size=test_batch_size,\n",
    "                                 shuffle=False, num_workers=2,drop_last=True, pin_memory=True)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = load_data(\n",
    "    args.training_size, args.training_batch_size, args.test_batch_size)\n",
    "\n",
    "\n",
    "train_loader, test_loader=list(train_loader), list(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to create a 1D datalodaer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DealDataset(Dataset):\n",
    "\n",
    "    def __init__(self, train_X, train_y):\n",
    "        self.x_data = train_X\n",
    "        self.y_data = train_y\n",
    "        self.len = train_X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class get_1D_data:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "    def get_target_func(self, x):\n",
    "\n",
    "        return torch.sin(x)+2*torch.sin(3*x)+3*torch.sin(5*x)\n",
    "    \n",
    "\n",
    "    def get_inputs(self):\n",
    "\n",
    "        args = self.args\n",
    "\n",
    "        bound=1\n",
    "\n",
    "        for i in range(2):\n",
    "            if isinstance(args.data_boundary[i], str):\n",
    "                args.data_boundary[i]=eval(args.data_boundary[i])\n",
    "\n",
    "        if args.input_dim == 1:\n",
    "\n",
    "            test_inputs = torch.reshape(torch.linspace(\n",
    "                bound*args.data_boundary[0], bound*args.data_boundary[1], args.test_size), [-1, 1])\n",
    "            train_inputs = torch.reshape(torch.linspace(\n",
    "                args.data_boundary[0], args.data_boundary[1], args.training_size), [-1, 1])\n",
    "        else:\n",
    "            test_inputs = (torch.rand(args.test_size, args.input_dim)\n",
    "                           )*(bound*args.data_boundary[1]-bound*args.data_boundary[0])+bound*args.data_boundary[0]\n",
    "            train_inputs = torch.rand(args.training_size, args.input_dim) *(args.data_boundary[1]-args.data_boundary[0])+args.data_boundary[0]\n",
    "        return test_inputs, train_inputs\n",
    "\n",
    "    def get_data(self):\n",
    "        test_inputs, train_inputs = self.get_inputs()\n",
    "        test_targets, train_targets = self.get_target_func(\n",
    "            test_inputs), self.get_target_func(train_inputs)\n",
    "        train_dataset = DealDataset(\n",
    "            train_inputs, train_targets)\n",
    "        test_dataset = DealDataset(\n",
    "            test_inputs, test_targets)\n",
    "        return train_dataset, test_dataset, test_inputs, train_inputs, test_targets, train_targets\n",
    "def load_data(training_batch_size, test_batch_size, args):\n",
    "\n",
    "    Get_data = get_1D_data(args)\n",
    "    train_dataset, test_dataset, _, _, _, _ = Get_data.get_data()\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                                batch_size=training_batch_size,\n",
    "                                shuffle=False,drop_last=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset,\n",
    "                                batch_size=test_batch_size,\n",
    "                                shuffle=False,drop_last=True)\n",
    "    \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network structure:\n",
      "My_CNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=12544, out_features=400, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=10, bias=True)\n",
      "    (3): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class My_CNN(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes: int = 10, act_layer: nn.Module = nn.ReLU()):\n",
    "        super(My_CNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    "        conv_layers: List[nn.Module] = []\n",
    "\n",
    "        conv_layers += [nn.Conv2d(self.in_channels,\n",
    "                             32, kernel_size=3,stride=1,padding=0), act_layer]\n",
    "        conv_layers += [nn.Conv2d(32, 64, kernel_size=3,stride=1,padding=0), act_layer]\n",
    "        conv_layers += [nn.MaxPool2d(kernel_size=(2, 2))]\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    "        mlp_layers: List[nn.Module] = []\n",
    "        mlp_layers += [nn.Linear(14*14*64, 400), act_layer]\n",
    "        mlp_layers += [nn.Linear(400, self.num_classes), nn.Softmax(dim=1)]\n",
    "        self.mlp = nn.Sequential(*mlp_layers)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self) -> None:\n",
    "        for obj in self.modules():\n",
    "            if isinstance(obj, (nn.Linear, nn.Conv2d)):\n",
    "                nn.init.xavier_uniform_(obj.weight.data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_act_func(act_func):\n",
    "    \"\"\"\n",
    "    Get activation function.\n",
    "\n",
    "    Args:\n",
    "        act_func (str): activation function name.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    if act_func == 'tanh':\n",
    "        return nn.Tanh()\n",
    "    elif act_func == 'ReLU':\n",
    "        return nn.ReLU()\n",
    "    elif act_func == 'Sigmoid':\n",
    "        return nn.Sigmoid()\n",
    "    else:\n",
    "        raise NameError('No such act func!')\n",
    "\n",
    "\n",
    "act_func = get_act_func(args.act_func_name)\n",
    "\n",
    "model = My_CNN(args.in_channel, args.num_classes, act_func).to(args.device)\n",
    "print(\"The network structure:\")\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-step training function.\n",
    "\n",
    "The training data set is denoted as  $S=\\{(x_i,y_i)\\}_{i=1}^n$, where $x_i\\in\\mathbb{R}^d$ and $y_i\\in \\mathbb{R}^{d'}$. For simplicity, we assume an unknown function $y$ satisfying $y(x_i)=y_i$ for $i\\in[n]$. The empirical risk reads as\n",
    "\\begin{equation*}\n",
    "    R_S(\\theta)=\\frac{1}{n}\\sum_{i=1}^n\\ell(f(x_i,\\theta),y(x_i)),\n",
    "\\end{equation*}\n",
    "where the loss function $\\ell(\\cdot,\\cdot)$ is differentiable and the derivative of $\\ell$ with respect to its first argument is denoted by $\\nabla\\ell(y,y^*)$. \n",
    "\n",
    "For a one-step gradient descent, we have, \n",
    "\n",
    "\\begin{equation*}\n",
    "    \\theta_{t+1}=\\theta_t-\\eta\\nabla R_S(\\theta).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_step(model, optimizer, loss_fn,  train_loader, args):\n",
    "    \"\"\"\n",
    "    It takes in a model, optimizer, loss function, resultsaver, train_loader, and args, and returns the\n",
    "    average loss and accuracy for the training set\n",
    "\n",
    "    :param model: the model we're training\n",
    "    :param optimizer: the optimizer for training model\n",
    "    :param loss_fn: the loss function\n",
    "    :param train_loader: the training data loader\n",
    "    :param args: a dictionary containing all the parameters for the training process\n",
    "    :return: The average loss and the accuracy\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    device = args.device\n",
    "\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "\n",
    "        batch_size = inputs.size(0)\n",
    "        total += batch_size\n",
    "\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = torch.autograd.Variable(\n",
    "            inputs), torch.autograd.Variable(targets)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(torch.log(outputs), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*batch_size\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += predicted.eq(targets.data).cpu().sum().item()\n",
    "\n",
    "    acc = 100*correct/total\n",
    "\n",
    "    return train_loss/total, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-step test function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loss_fn, test_loader,  args):\n",
    "    \"\"\"\n",
    "    It takes a model, a test_loader, a loss function, and some arguments, and returns the average loss\n",
    "    and accuracy of the model on the test set.\n",
    "\n",
    "    :param model: the model\n",
    "    :param loss_fn: the loss function\n",
    "    :param test_loader: a DataLoader object\n",
    "    :param args: a dictionary containing all the parameters for the training process\n",
    "    :return: The loss and accuracy of the model on the test set.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    device = args.device\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            batch_size = inputs.size(0)\n",
    "            total += batch_size\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs, targets = torch.autograd.Variable(\n",
    "                inputs), torch.autograd.Variable(targets)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(torch.log(outputs), targets)\n",
    "            train_loss += loss.item() * batch_size\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += predicted.eq(targets.data).cpu().sum().item()\n",
    "        acc = 100 * correct / total\n",
    "    return train_loss / total, acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to obtain model output on the full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, training_loader,  args):\n",
    "    \"\"\"\n",
    "    It takes a model, a test_loader, a loss function, and some arguments, and returns the average loss\n",
    "    and accuracy of the model on the test set.\n",
    "\n",
    "    :param model: the model\n",
    "    :param training_loader: a DataLoader object\n",
    "    :param args: a dictionary containing all the parameters for the training process\n",
    "    :return: the outputs of the model on the training set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    y_pred =[]\n",
    "\n",
    "    device = args.device\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in training_loader:\n",
    "\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs, targets = torch.autograd.Variable(\n",
    "                inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            y_pred.append(outputs)\n",
    "\n",
    "    return torch.cat(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(path, loss_train, x_log=False):\n",
    "    \"\"\"\n",
    "    Plot loss.\n",
    "\n",
    "    Args:\n",
    "        path (str): path.\n",
    "        loss_train (list): list of training loss.\n",
    "        x_log (bool): whether to use log scale for x-axis.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.gca()\n",
    "    y2 = np.asarray(loss_train)\n",
    "    plt.plot(y2, 'k-', label='Train')\n",
    "    plt.xlabel('epoch', fontsize=18)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    plt.yscale('log')\n",
    "    if x_log == False:\n",
    "        fntmp = os.path.join(path, 'loss.jpg')\n",
    "\n",
    "    else:\n",
    "        plt.xscale('log')\n",
    "        fntmp = os.path.join(path, 'loss_log.jpg')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fntmp, dpi=300)\n",
    "\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering\n",
    "For the original dataset $\\left\\{\\left(x_i, y_i\\right)\\right\\}_{i=0}^{n-1}$, such as MNIST or CIFAR10. $x_i$ is an image vector, $y_i$ is a one-hot vector. The low frequency part can be derived by\n",
    "$$\n",
    "y_i^{\\mathrm{low}, \\delta}=\\frac{1}{C_i} \\sum_{j=0}^{n-1} y_j G^\\delta\\left(x_i-x_j\\right),\n",
    "$$\n",
    "where $C_i=\\sum_{j=0}^{n-1} G^\\delta\\left(x_i-x_j\\right)$ is a normalization factor and\n",
    "$$\n",
    "G^\\delta\\left(x_i-x_j\\right)=\\exp \\left(-\\left|x_i-x_j\\right|^2 /(2 \\delta)\\right).\n",
    "$$\n",
    "The high frequency part can be derived by $\\boldsymbol{y}_i^{\\text {high, } \\delta} \\triangleq \\boldsymbol{y}_i-\\boldsymbol{y}_i^{\\text {low }, \\delta}$. We also compute $\\boldsymbol{h}_i^{\\text {low, } \\delta}$ and $\\boldsymbol{h}_i^{\\text {high, } \\delta}$ for each DNN output $\\boldsymbol{h}_i$.\n",
    "Then, we can examine\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& e_{\\text {low }}=\\left(\\frac{\\sum_i\\left|\\boldsymbol{y}_i^{\\text {low }, \\delta}-\\boldsymbol{h}_i^{\\text {low }, \\delta}\\right|^2}{\\sum_i\\left|\\boldsymbol{y}_i^{\\text {low }, \\delta}\\right|^2}\\right)^{\\frac{1}{2}}, \\\\\n",
    "& e_{\\text {high }}=\\left(\\frac{\\sum_i\\left|\\boldsymbol{y}_i^{\\text {high }, \\delta}-\\boldsymbol{h}_i^{\\text {high }, \\delta}\\right|^2}{\\sum_i\\left|y_i^{\\text {high }, \\delta}\\right|^2}\\right)^{\\frac{1}{2}}.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def compute_distance(matrix):\n",
    "#     \"\"\"   \n",
    "#     A more intuitive way to calculate the pairwise Euclidean distance, but it will consume a lot of memory.\n",
    "#     \"\"\"\n",
    "#     diff = matrix[:, np.newaxis, :] - matrix[np.newaxis, :, :]\n",
    "#     return np.sum(diff**2, axis=2)\n",
    "\n",
    "\n",
    "\n",
    "def compute_distance_for_training_loader(training_loader):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the pairwise Euclidean distance between all pairs of flattened images in a training loader.\n",
    "\n",
    "    Args:\n",
    "        training_loader (DataLoader): A DataLoader object containing the training data.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 2D NumPy array of shape [N, N], where N is the number of images in the training set.\n",
    "    \"\"\"\n",
    "\n",
    "    data_list = [data for data, _ in training_loader]\n",
    "\n",
    "    # Concatenate the list of data into a single tensor\n",
    "    data = torch.cat(data_list)\n",
    "    # Reshape data into [B, C*H*W]\n",
    "    flattened_images = data.view(data.shape[0], -1).numpy()\n",
    "\n",
    "    dist = -2 * np.dot(flattened_images, flattened_images.T) + np.sum(flattened_images**2, axis=1) + \\\n",
    "        np.sum(flattened_images**2, axis=1)[:, np.newaxis]\n",
    "    return dist\n",
    "\n",
    "\n",
    "def normal_kernel(dist, filter_dict):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the normalized Gaussian kernel for each filter in the filter dictionary.\n",
    "\n",
    "    Args:\n",
    "        dist (np.ndarray): A 2D NumPy array of pairwise distances between data points.\n",
    "        filter_dict (list): A list of filter values to use for each kernel.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of 2D NumPy arrays, where each array is a normalized Gaussian kernel for a filter in the filter dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    kernel_dict = []\n",
    "    for filter in filter_dict:\n",
    "        kernel = np.exp(-dist / 2 / filter)\n",
    "        mean = np.sum(kernel, axis=1, keepdims=True)\n",
    "        kernel_dict.append(kernel/mean)\n",
    "    return kernel_dict\n",
    "\n",
    "\n",
    "def gauss_filiter(f_orig, kernel):\n",
    "\n",
    "    \"\"\"\n",
    "    Applies a Gaussian filter to an image output.\n",
    "\n",
    "    Args:\n",
    "        f_orig (np.ndarray): A 2D NumPy array representing the model output.\n",
    "        kernel (np.ndarray): A 2D NumPy array representing the Gaussian kernel.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 2D NumPy array representing the filtered output.\n",
    "    \"\"\"\n",
    "\n",
    "    return np.matmul(kernel, f_orig)\n",
    "\n",
    "\n",
    "def get_freq_low_high(yy, kernel_dict):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the low and high frequency components of the model output using a set of Gaussian filters.\n",
    "\n",
    "    Args:\n",
    "        yy (np.ndarray): NumPy array representing the model output.\n",
    "        kernel_dict (list): A list of 2D NumPy arrays representing the Gaussian kernels to use for filtering.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of two lists, where the first list contains the low frequency components of\n",
    "                the model output and the second list contains the high frequency components of the model output.\n",
    "    \"\"\"\n",
    "    f_low = []\n",
    "    f_high = []\n",
    "    for filter in range(len(kernel_dict)):\n",
    "        kernel = kernel_dict[filter]\n",
    "        f_new_norm = gauss_filiter(yy, kernel)\n",
    "        f_low.append(f_new_norm)\n",
    "        f_high_tmp = yy - f_new_norm\n",
    "        f_high.append(f_high_tmp)\n",
    "\n",
    "    return f_low, f_high \n",
    "\n",
    "def get_target_freq_distr(train_labels, dist, filter_start, filter_end, filter_num):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the target frequency distribution of a set of training labels using a set of Gaussian filters.\n",
    "\n",
    "    Args:\n",
    "        train_labels (np.ndarray): NumPy array representing the training labels.\n",
    "        dist (np.ndarray): A 2D NumPy array of pairwise Euclidean distance between all pairs of flattened images in a training loader.\n",
    "        filter_start (float): The starting value of the filter range.\n",
    "        filter_end (float): The ending value of the filter range.\n",
    "        filter_num (int): The number of filters to use in the filter range.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple of four elements, where the first element is a 1D NumPy array of filter values, \n",
    "                the second element is a list of 2D NumPy arrays representing the Gaussian kernels used for filtering, \n",
    "                the third element is a list of 1D NumPy arrays representing the low frequency components of the training labels, \n",
    "                and the fourth element is a list of 1D NumPy arrays representing the high frequency components of the training labels.\n",
    "    \"\"\"\n",
    "\n",
    "    filter_dict = np.linspace(\n",
    "        filter_start, filter_end, num=filter_num)\n",
    "\n",
    "    kernel_dict = normal_kernel(dist, filter_dict)\n",
    "    f_low, f_high = get_freq_low_high(train_labels, kernel_dict)\n",
    "\n",
    "    return filter_dict, kernel_dict, f_low, f_high\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examination. \n",
    "\n",
    "Plot the relative error $e_{\\text {low }}$ and $e_{\\text {high }}$ at each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff_distr(filter, lowdiff, highdiff, args):\n",
    "\n",
    "    \"\"\"\n",
    "    Plots the difference between the low and high frequency components of the predicted labels and the targets.\n",
    "\n",
    "    Args:\n",
    "        filter (float): The filter value used for filtering.\n",
    "        lowdiff (list): A list of relative distances between the low frequency components of the predicted labels and targets.\n",
    "        highdiff (list): A list of relative distances between the high frequency components of the predicted labels and targets.\n",
    "        args (argparse.Namespace): An argparse Namespace object containing the path to save the plot.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title('freq with filter {:.02f}'.format(filter))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(lowdiff, 'r-', label='low_{:.02f}'.format(filter))\n",
    "    plt.plot(highdiff, 'b-', label='high_{:0.2f}'.format(filter))\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('freq')\n",
    "    plt.subplot(122)\n",
    "    tmp = np.stack([lowdiff, highdiff])\n",
    "    plt.pcolor(tmp, cmap='RdBu', vmin=0.1, vmax=1)\n",
    "    plt.colorbar()\n",
    "    plt.yticks([0.6, 1.6], ('low freq', 'high freq'), rotation='vertical')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.savefig(args.path + '/hot_{:0.2f}.png'.format(filter))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the high and low frequency distribution of targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dist = compute_distance_for_training_loader(train_loader)\n",
    "\n",
    "target_list = [target for data, target in train_loader]\n",
    "\n",
    "targets = torch.cat(target_list)\n",
    "\n",
    "\n",
    "train_labels = F.one_hot(targets, num_classes=10).detach().cpu().numpy()\n",
    "\n",
    "filter_dict, kernel_dict, f_low, f_high=get_target_freq_distr(train_labels, dist, args.start_filter, args.end_filter, args.num_filter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 2.242450 acc: 17.92 valloss: 2.159925 valacc: 21.31 time: 1.59 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15853\\AppData\\Local\\Temp\\ipykernel_28172\\1689078004.py:25: UserWarning: Data has no positive values, and therefore cannot be log-scaled.\n",
      "  plt.xscale('log')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] loss: 2.052028 acc: 27.12 valloss: 1.996363 valacc: 25.72 time: 3.47 s\n",
      "[3] loss: 1.936158 acc: 30.56 valloss: 1.931272 valacc: 29.31 time: 5.42 s\n",
      "[4] loss: 1.868892 acc: 33.26 valloss: 1.878936 valacc: 31.99 time: 7.29 s\n",
      "[5] loss: 1.809480 acc: 35.92 valloss: 1.838458 valacc: 33.74 time: 9.25 s\n",
      "[6] loss: 1.755355 acc: 38.40 valloss: 1.805159 valacc: 35.09 time: 11.00 s\n",
      "[7] loss: 1.705256 acc: 40.20 valloss: 1.773306 valacc: 36.25 time: 12.95 s\n",
      "[8] loss: 1.658944 acc: 41.72 valloss: 1.744390 valacc: 37.58 time: 14.75 s\n",
      "[9] loss: 1.614242 acc: 43.70 valloss: 1.715700 valacc: 38.29 time: 16.56 s\n",
      "[10] loss: 1.569963 acc: 45.12 valloss: 1.689183 valacc: 39.37 time: 18.57 s\n",
      "[11] loss: 1.525250 acc: 47.24 valloss: 1.661363 valacc: 40.43 time: 20.47 s\n",
      "[12] loss: 1.479460 acc: 48.86 valloss: 1.635603 valacc: 41.47 time: 22.40 s\n",
      "[13] loss: 1.432439 acc: 50.48 valloss: 1.607664 valacc: 42.41 time: 24.40 s\n",
      "[14] loss: 1.384860 acc: 52.32 valloss: 1.580998 valacc: 43.48 time: 26.26 s\n",
      "[15] loss: 1.338627 acc: 54.18 valloss: 1.557561 valacc: 44.29 time: 28.03 s\n",
      "[16] loss: 1.291658 acc: 55.70 valloss: 1.534693 valacc: 45.24 time: 29.96 s\n",
      "[17] loss: 1.245911 acc: 57.54 valloss: 1.520419 valacc: 45.90 time: 31.68 s\n",
      "[18] loss: 1.200853 acc: 59.52 valloss: 1.505639 valacc: 46.64 time: 33.36 s\n",
      "[19] loss: 1.156061 acc: 61.20 valloss: 1.496528 valacc: 47.12 time: 35.07 s\n",
      "[20] loss: 1.111681 acc: 62.90 valloss: 1.488500 valacc: 47.57 time: 37.01 s\n",
      "[21] loss: 1.065338 acc: 64.42 valloss: 1.483422 valacc: 47.87 time: 38.81 s\n",
      "[22] loss: 1.019369 acc: 65.92 valloss: 1.480754 valacc: 48.08 time: 40.57 s\n",
      "[23] loss: 0.971426 acc: 67.84 valloss: 1.481229 valacc: 48.14 time: 42.35 s\n",
      "[24] loss: 0.922365 acc: 69.62 valloss: 1.489264 valacc: 48.27 time: 44.32 s\n",
      "[25] loss: 0.872228 acc: 71.34 valloss: 1.498970 valacc: 48.43 time: 45.96 s\n",
      "[26] loss: 0.821267 acc: 73.22 valloss: 1.512675 valacc: 48.58 time: 47.60 s\n",
      "[27] loss: 0.768954 acc: 75.58 valloss: 1.531128 valacc: 48.62 time: 49.28 s\n",
      "[28] loss: 0.715684 acc: 77.66 valloss: 1.555631 valacc: 48.70 time: 51.00 s\n",
      "[29] loss: 0.662141 acc: 79.74 valloss: 1.584454 valacc: 48.80 time: 52.94 s\n",
      "[30] loss: 0.608483 acc: 82.34 valloss: 1.618428 valacc: 48.76 time: 54.66 s\n",
      "[31] loss: 0.554494 acc: 84.28 valloss: 1.661999 valacc: 48.54 time: 56.44 s\n",
      "[32] loss: 0.502590 acc: 86.48 valloss: 1.701143 valacc: 48.47 time: 58.19 s\n",
      "[33] loss: 0.452515 acc: 88.50 valloss: 1.749106 valacc: 48.44 time: 59.98 s\n",
      "[34] loss: 0.404588 acc: 90.10 valloss: 1.798949 valacc: 48.31 time: 61.79 s\n",
      "[35] loss: 0.359553 acc: 91.70 valloss: 1.852193 valacc: 48.53 time: 63.88 s\n",
      "[36] loss: 0.317202 acc: 93.42 valloss: 1.911344 valacc: 48.31 time: 65.67 s\n",
      "[37] loss: 0.278849 acc: 94.48 valloss: 1.969513 valacc: 48.16 time: 67.45 s\n",
      "[38] loss: 0.244016 acc: 95.48 valloss: 2.031964 valacc: 48.34 time: 69.26 s\n",
      "[39] loss: 0.213388 acc: 96.64 valloss: 2.098185 valacc: 48.21 time: 70.96 s\n",
      "[40] loss: 0.186528 acc: 97.28 valloss: 2.159169 valacc: 47.95 time: 72.57 s\n",
      "[41] loss: 0.164689 acc: 97.78 valloss: 2.217817 valacc: 48.00 time: 74.16 s\n",
      "[42] loss: 0.145779 acc: 98.18 valloss: 2.271468 valacc: 48.20 time: 76.13 s\n",
      "[43] loss: 0.128995 acc: 98.40 valloss: 2.324845 valacc: 48.33 time: 77.79 s\n",
      "[44] loss: 0.115003 acc: 99.00 valloss: 2.373457 valacc: 48.37 time: 79.39 s\n",
      "[45] loss: 0.102952 acc: 99.28 valloss: 2.440753 valacc: 48.20 time: 81.07 s\n",
      "[46] loss: 0.093445 acc: 99.24 valloss: 2.501447 valacc: 48.08 time: 82.74 s\n",
      "[47] loss: 0.085656 acc: 99.38 valloss: 2.549903 valacc: 48.02 time: 84.49 s\n",
      "[48] loss: 0.078228 acc: 99.40 valloss: 2.638650 valacc: 47.89 time: 86.26 s\n",
      "[49] loss: 0.071335 acc: 99.52 valloss: 2.713143 valacc: 47.58 time: 88.00 s\n",
      "[50] loss: 0.063769 acc: 99.68 valloss: 2.674871 valacc: 48.04 time: 89.78 s\n",
      "[51] loss: 0.057586 acc: 99.70 valloss: 2.652137 valacc: 48.92 time: 91.93 s\n",
      "[52] loss: 0.052165 acc: 99.72 valloss: 2.637785 valacc: 49.28 time: 93.67 s\n",
      "[53] loss: 0.047869 acc: 99.86 valloss: 2.668156 valacc: 49.44 time: 95.42 s\n",
      "[54] loss: 0.044775 acc: 99.76 valloss: 2.728125 valacc: 49.44 time: 97.25 s\n",
      "[55] loss: 0.042492 acc: 99.78 valloss: 2.787550 valacc: 49.23 time: 99.14 s\n",
      "[56] loss: 0.039660 acc: 99.86 valloss: 2.837990 valacc: 49.26 time: 100.89 s\n",
      "[57] loss: 0.036365 acc: 99.82 valloss: 2.833091 valacc: 49.40 time: 102.63 s\n",
      "[58] loss: 0.035091 acc: 99.76 valloss: 2.833712 valacc: 49.42 time: 104.33 s\n",
      "[59] loss: 0.030627 acc: 99.76 valloss: 2.800908 valacc: 49.74 time: 106.04 s\n",
      "[60] loss: 0.025465 acc: 99.88 valloss: 2.778563 valacc: 49.93 time: 107.74 s\n",
      "[61] loss: 0.021253 acc: 99.92 valloss: 2.796755 valacc: 49.88 time: 109.91 s\n",
      "[62] loss: 0.019122 acc: 99.96 valloss: 2.821101 valacc: 49.81 time: 111.59 s\n",
      "[63] loss: 0.017305 acc: 99.96 valloss: 2.844254 valacc: 49.93 time: 113.30 s\n",
      "[64] loss: 0.015662 acc: 99.98 valloss: 2.856637 valacc: 50.12 time: 114.95 s\n",
      "[65] loss: 0.014269 acc: 100.00 valloss: 2.871623 valacc: 50.09 time: 116.63 s\n",
      "[66] loss: 0.013057 acc: 100.00 valloss: 2.897642 valacc: 50.30 time: 118.32 s\n",
      "[67] loss: 0.012155 acc: 100.00 valloss: 2.919202 valacc: 50.25 time: 119.95 s\n",
      "[68] loss: 0.011309 acc: 100.00 valloss: 2.939320 valacc: 50.32 time: 121.65 s\n",
      "[69] loss: 0.010608 acc: 100.00 valloss: 2.956045 valacc: 50.27 time: 123.36 s\n",
      "[70] loss: 0.010038 acc: 100.00 valloss: 2.968906 valacc: 50.31 time: 125.09 s\n",
      "[71] loss: 0.009527 acc: 100.00 valloss: 2.981077 valacc: 50.39 time: 126.86 s\n",
      "[72] loss: 0.009095 acc: 100.00 valloss: 2.989969 valacc: 50.40 time: 129.15 s\n",
      "[73] loss: 0.008691 acc: 100.00 valloss: 2.998950 valacc: 50.36 time: 130.92 s\n",
      "[74] loss: 0.008281 acc: 99.98 valloss: 3.007993 valacc: 50.37 time: 132.66 s\n",
      "[75] loss: 0.007778 acc: 100.00 valloss: 3.019728 valacc: 50.45 time: 134.34 s\n",
      "[76] loss: 0.007330 acc: 100.00 valloss: 3.033074 valacc: 50.38 time: 136.07 s\n",
      "[77] loss: 0.006937 acc: 100.00 valloss: 3.042401 valacc: 50.36 time: 137.80 s\n",
      "[78] loss: 0.006634 acc: 100.00 valloss: 3.050151 valacc: 50.33 time: 139.55 s\n",
      "[79] loss: 0.006343 acc: 100.00 valloss: 3.054113 valacc: 50.42 time: 141.30 s\n",
      "[80] loss: 0.006068 acc: 100.00 valloss: 3.057931 valacc: 50.40 time: 143.00 s\n",
      "[81] loss: 0.005805 acc: 100.00 valloss: 3.062328 valacc: 50.49 time: 144.71 s\n",
      "[82] loss: 0.005571 acc: 100.00 valloss: 3.069287 valacc: 50.53 time: 146.44 s\n",
      "[83] loss: 0.005358 acc: 100.00 valloss: 3.077592 valacc: 50.52 time: 148.19 s\n",
      "[84] loss: 0.005166 acc: 100.00 valloss: 3.085815 valacc: 50.65 time: 150.62 s\n",
      "[85] loss: 0.004979 acc: 100.00 valloss: 3.093081 valacc: 50.63 time: 152.38 s\n",
      "[86] loss: 0.004793 acc: 100.00 valloss: 3.100326 valacc: 50.64 time: 154.14 s\n",
      "[87] loss: 0.004622 acc: 100.00 valloss: 3.106754 valacc: 50.65 time: 155.90 s\n",
      "[88] loss: 0.004460 acc: 100.00 valloss: 3.111502 valacc: 50.65 time: 157.68 s\n",
      "[89] loss: 0.004300 acc: 100.00 valloss: 3.115537 valacc: 50.63 time: 159.46 s\n",
      "[90] loss: 0.004148 acc: 100.00 valloss: 3.119317 valacc: 50.75 time: 161.24 s\n",
      "[91] loss: 0.003991 acc: 100.00 valloss: 3.123444 valacc: 50.88 time: 162.99 s\n",
      "[92] loss: 0.003844 acc: 100.00 valloss: 3.128710 valacc: 50.91 time: 164.75 s\n",
      "[93] loss: 0.003700 acc: 100.00 valloss: 3.135732 valacc: 50.70 time: 166.49 s\n",
      "[94] loss: 0.003561 acc: 100.00 valloss: 3.144808 valacc: 50.75 time: 168.28 s\n",
      "[95] loss: 0.003429 acc: 100.00 valloss: 3.154502 valacc: 50.77 time: 170.06 s\n",
      "[96] loss: 0.003311 acc: 100.00 valloss: 3.164342 valacc: 50.64 time: 172.80 s\n",
      "[97] loss: 0.003198 acc: 100.00 valloss: 3.174051 valacc: 50.61 time: 174.58 s\n",
      "[98] loss: 0.003095 acc: 100.00 valloss: 3.183002 valacc: 50.63 time: 176.35 s\n",
      "[99] loss: 0.002997 acc: 100.00 valloss: 3.189540 valacc: 50.64 time: 178.14 s\n",
      "[100] loss: 0.002911 acc: 100.00 valloss: 3.195873 valacc: 50.61 time: 179.90 s\n",
      "[101] loss: 0.002830 acc: 100.00 valloss: 3.200736 valacc: 50.69 time: 181.70 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "if args.optimizer == 'sgd':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "elif args.optimizer == 'nesterov':\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr=args.lr, momentum=0.9, nesterov=True)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "lowdiff = [[] for _ in range(len(filter_dict))]\n",
    "highdiff = [[] for _ in range(len(filter_dict))]\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "args.loss_training_lst = []\n",
    "\n",
    "for epoch in range(args.epochs+1):\n",
    "\n",
    "    model.train()\n",
    "    loss, acc = train_one_step(\n",
    "        model, optimizer, loss_fn, train_loader, args)\n",
    "    loss_test, acc_test = test(\n",
    "        model, loss_fn, test_loader, args)\n",
    "    y_pred=val(model, train_loader, args)\n",
    "    f_train_low, f_train_high=get_freq_low_high(y_pred.detach().cpu().numpy(), kernel_dict)\n",
    "\n",
    "    for i in range(len(filter_dict)):\n",
    "        lowdiff[i].append(np.linalg.norm(\n",
    "            f_train_low[i] - f_low[i])/np.linalg.norm(f_low[i]))\n",
    "        highdiff[i].append(np.linalg.norm(\n",
    "            f_train_high[i] - f_high[i])/np.linalg.norm(f_high[i]))\n",
    "\n",
    "    args.loss_training_lst.append(loss)\n",
    "\n",
    "    if epoch % args.plot_epoch == 0:\n",
    "          print(\"[%d] loss: %.6f acc: %.2f valloss: %.6f valacc: %.2f time: %.2f s\" %\n",
    "                (epoch + 1, loss, acc, loss_test, acc_test, (time.time()-t0)))\n",
    "\n",
    "    if (epoch+1) % (args.plot_epoch) == 0:\n",
    "          plot_loss(path=args.path,\n",
    "                    loss_train=args.loss_training_lst, x_log=True)\n",
    "          plot_loss(path=args.path,\n",
    "                    loss_train=args.loss_training_lst, x_log=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the frequency difference distribution between the predicted labels and the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9302450443059735, 0.9069813183594942, 0.8950565451780425, 0.8840746533431112, 0.8743595336163951, 0.8655244913726188, 0.856922558964229, 0.8485899743996339, 0.8398948319403262, 0.8309498837335527, 0.821133519683297, 0.810829310897514, 0.7990789370288055, 0.786637135174792, 0.773834749175389, 0.759916514775445, 0.7472096204417576, 0.7332194949325487, 0.7197749971603593, 0.7059715347396728, 0.6898989891226106, 0.6750486783805574, 0.6588363336335504, 0.6434937773604864, 0.6269224757506783, 0.6094565793936777, 0.5929058582332037, 0.575419458391751, 0.5578804787035574, 0.5397063887832478, 0.5247074879526371, 0.506290992208222, 0.49015277244200767, 0.47219634278706135, 0.45579836429086645, 0.4409519939236635, 0.42821514966885865, 0.4155128909416621, 0.4071794032436354, 0.39378714404165155, 0.38123632374919664, 0.36343583580843125, 0.3479937007774462, 0.33131177633926406, 0.32378981556120456, 0.31652293193877684, 0.30710494674202504, 0.3147636026247451, 0.3186779861057221, 0.2685306710781816, 0.22494853350779315, 0.19554420874169526, 0.19471848922581558, 0.21232012358470134, 0.22863176266620813, 0.24159733858811025, 0.23040085404863445, 0.2142576343605193, 0.1626220318462785, 0.12321115345883374, 0.11592588870755044, 0.12029409194057333, 0.119845006958211, 0.10811964050962461, 0.09489484801047454, 0.08959027332002278, 0.08607148769955306, 0.08329903915505356, 0.08110296775026099, 0.07820971674377325, 0.07561817246243496, 0.07306057344245291, 0.07046784020933451, 0.06835675006178835, 0.06650906232157543, 0.06463846313109325, 0.06208214994848968, 0.0592468073549775, 0.0559003031011291, 0.05149009916636938, 0.046606630206974746, 0.043460837242714385, 0.04188229005756945, 0.040857069254835884, 0.03839833838421987, 0.03639818155977338, 0.034221726275344845, 0.031204075298703136, 0.02793978405402279, 0.02420049572714993, 0.020685111205311673, 0.01738601855574927, 0.01574088502945878, 0.015622227047131293, 0.016450588001339948, 0.017953402288461724, 0.019168167957794677, 0.019862243364218185, 0.019424502617586423, 0.01868802151610637, 0.01755369310870472], [0.921732797490339, 0.8964251224076061, 0.8836850122342742, 0.8720756394585609, 0.8619783335514526, 0.85286437077561, 0.8439686059439556, 0.8353882888051866, 0.8264212149274259, 0.8171647748909117, 0.8070227928339708, 0.7964193903991797, 0.7842576840691886, 0.7714007541218879, 0.7582254575424174, 0.7438216227833385, 0.7307968191122924, 0.7163204545455029, 0.7024522713054414, 0.6882056798106608, 0.6715340853224209, 0.656252714501814, 0.6394565495075499, 0.6236345497708532, 0.6064638607183723, 0.588395474175228, 0.5713412252848089, 0.5534639257269458, 0.5353679714091502, 0.5169700715415796, 0.5020364275235544, 0.48350809501603015, 0.46765306527297296, 0.45013467837801346, 0.4343012783059328, 0.42037622193618585, 0.40892339246075493, 0.39754857598629023, 0.39048716594233335, 0.3779804800721778, 0.3662383389162099, 0.3490771789245212, 0.3347543541666112, 0.3191785489719334, 0.3133673854755001, 0.3074399842189407, 0.2996704175413189, 0.30838072441337955, 0.31286480366340513, 0.26248719792621217, 0.21925943122034197, 0.18867736925750628, 0.1864418559361516, 0.20236509124805138, 0.2178487860080437, 0.2310827525353688, 0.2203662883392382, 0.20560572376036804, 0.1558655034450379, 0.11767519990965218, 0.1107531546492902, 0.11585809364836362, 0.11571574069996575, 0.10381428896895321, 0.09008493325049298, 0.0843343060510353, 0.08051672106793041, 0.07769303131544537, 0.07535029110921596, 0.0722493426809371, 0.06943614206388857, 0.06658284447151501, 0.06382406811790432, 0.06168132819202296, 0.05960664289761613, 0.057983284452176515, 0.05584645037449445, 0.05335842242254676, 0.05028554959075731, 0.0462490087781181, 0.041864151524413515, 0.03925301411562791, 0.03809012687854344, 0.03742201624982201, 0.03545645940597188, 0.03377668289974679, 0.03185749392023359, 0.029117101725916972, 0.026035051174784007, 0.022463414259415553, 0.019064042698270688, 0.015738737864013103, 0.014079443765163874, 0.013956605420671741, 0.014880359295244242, 0.01646396230282876, 0.017773460349131572, 0.018489770905746446, 0.01810493522042772, 0.01746517307984759, 0.016390206134608027], [0.8693926098493211, 0.8361449185315821, 0.821212323083517, 0.8075310678120872, 0.7956276954252544, 0.7851682341654699, 0.7755824216047585, 0.76649495083779, 0.7572313930491856, 0.7473375487404891, 0.7366331647977218, 0.7258556400865507, 0.7127216409348133, 0.6990064753903513, 0.6853011881438962, 0.6698655670351783, 0.6565351195413885, 0.6415336969384582, 0.6274983277105687, 0.6131883138475787, 0.5958734185576801, 0.5809885098629308, 0.5644478155442438, 0.5494038354104931, 0.5330808325858823, 0.515770919854484, 0.5002614222962557, 0.4836323665211226, 0.46719862736140055, 0.45118027029310687, 0.43896523284225136, 0.42271847600850393, 0.4098990475652877, 0.3954812285012, 0.3826058962554943, 0.37341464498556826, 0.366762857819032, 0.35958810862838325, 0.3565494467225451, 0.34569547666765826, 0.3345439292034292, 0.3180766379373789, 0.30489745664388984, 0.2903219178070654, 0.28652074118893517, 0.2828704080044291, 0.27819845430474277, 0.28970908617718694, 0.2966800563716703, 0.24308821841201292, 0.20067252840650396, 0.16931296948835955, 0.16361684691704273, 0.1775122400281511, 0.19418926199343745, 0.21099130553494191, 0.20190676136076932, 0.1895851477773185, 0.14270570781923564, 0.10173782182197294, 0.0935510343327251, 0.10053074265539254, 0.10228822305160011, 0.09176990095222652, 0.07949196969107422, 0.07444632685197654, 0.07092209602805426, 0.06813261866083647, 0.06555181976831226, 0.06196693843011292, 0.05847088248090621, 0.05450049945289299, 0.05133788614464505, 0.04890738853743833, 0.04662996333448385, 0.04510519913162455, 0.04294185045178431, 0.04068659307308093, 0.03786467401182561, 0.034782946606627334, 0.0317371226124791, 0.030010952414382917, 0.029429514565903953, 0.029079857252376867, 0.02778295281051676, 0.026414788950076873, 0.024592928669371145, 0.022157074445007887, 0.019292365230393214, 0.01639124289744228, 0.013770454136957141, 0.011695346985896495, 0.010943615175391871, 0.011504753683886383, 0.012941222296322228, 0.014841496312084392, 0.01635616391671623, 0.017142683794460732, 0.016732666888499427, 0.016268354041725844, 0.015218267463462996], [0.7436435773617364, 0.6990995240456741, 0.6830453010746924, 0.666471706852803, 0.6503644189293416, 0.6374012975000518, 0.6280582812755956, 0.6203237593443701, 0.6129387364594203, 0.603816163829104, 0.5949540600342957, 0.5862138833482377, 0.5729308419989466, 0.5595439554195104, 0.5474017750368786, 0.5325205476210949, 0.5210044465246465, 0.5075657017974144, 0.4955696338357665, 0.4842335766366648, 0.46843214919630244, 0.45695767760010964, 0.444302793325185, 0.43335031969734844, 0.422623898429582, 0.4101200557501346, 0.40140560692740124, 0.39071091827484433, 0.38147116953881877, 0.3726983305496507, 0.3680895754012991, 0.3598025448850456, 0.35476922706145814, 0.34759175836849154, 0.3402191032484859, 0.33633154371064883, 0.3338754618713717, 0.32925527780372726, 0.3316020858378495, 0.32320576311349125, 0.31319657449446, 0.2967766312075857, 0.28404009107763906, 0.2686448650416236, 0.2649166365587593, 0.2623066425210806, 0.2569470344233897, 0.26951282389700637, 0.2817920209986071, 0.22151313485788307, 0.17848454135323008, 0.1484831933778036, 0.142170114972701, 0.15931630347821119, 0.17990822363219777, 0.1992979628250325, 0.1911950273309975, 0.1772584848483225, 0.1252331985047838, 0.08672956079661255, 0.07908942049691302, 0.08828012181397842, 0.09147552899239647, 0.080842486445218, 0.0691251390345005, 0.06504879073309766, 0.06252597877185918, 0.06036696511946348, 0.058108235302251496, 0.05489518137867702, 0.05151445771230435, 0.048067699494792615, 0.04540566888113008, 0.04316799961578607, 0.04119386445452422, 0.03927002677976675, 0.03678182440276754, 0.034235744465003166, 0.03145282949581651, 0.028658788991137357, 0.026188993974235568, 0.024763010534467188, 0.024292722947646835, 0.023998419875773325, 0.02308313115946246, 0.021903251640629902, 0.02030430168345783, 0.018157418288248427, 0.0154844756516972, 0.012912374974088942, 0.010557913303479122, 0.008881560075278589, 0.008276712725470594, 0.008696420878208572, 0.009747824404083423, 0.011268307118315958, 0.012441782698283863, 0.013152508540816248, 0.012862405210013675, 0.012491570710902905, 0.011667729213776705], [0.5840241479316859, 0.529134197632855, 0.5130038196705705, 0.49313108601108435, 0.47077579637738054, 0.4543132943205104, 0.44621420315703464, 0.44191409100489504, 0.43847075663914864, 0.4317722849213888, 0.4272283482189614, 0.42283661985299126, 0.4103792435044992, 0.39875524539022716, 0.39056771663511314, 0.3778424401410447, 0.37119565482830486, 0.36118479058616015, 0.3539995499460021, 0.3489782714382293, 0.33663909857722585, 0.3315032448388263, 0.32579885122918933, 0.3219973627505263, 0.3207866253588154, 0.31594871904152433, 0.3173144615530977, 0.31491717188206203, 0.31572164300905625, 0.31563992398037327, 0.3197852601435021, 0.3199369205277897, 0.3221021050593585, 0.32049040416026364, 0.3168099074788656, 0.31453084663322683, 0.3132760004109717, 0.30817733355426735, 0.3131069946201708, 0.30540641288564596, 0.29574136850455707, 0.2783845082182336, 0.2649247968733742, 0.24703467477101104, 0.24326763722293643, 0.24052698608173861, 0.2344238516183464, 0.25011958356901925, 0.2670303402139101, 0.20196527346334514, 0.1538900915605434, 0.12404940597911109, 0.12021870552503269, 0.14178423486719643, 0.16515932737135353, 0.18553745111582495, 0.1777708015504701, 0.1609419716244305, 0.10370888106858998, 0.07201213070139055, 0.06786252622290291, 0.07958746879051186, 0.08373934755704149, 0.07393492396228692, 0.06334935586970841, 0.06010103567758172, 0.0583122499061844, 0.056555838109411345, 0.055083735946270765, 0.052969562038763136, 0.05057335242577495, 0.04813877385265794, 0.04623424189567279, 0.04434201818939734, 0.042626096909350174, 0.040612869022332604, 0.0378055496171159, 0.0348462111538273, 0.031664357545143976, 0.028478014301343547, 0.025669959486679935, 0.0238035802763884, 0.022726525099720937, 0.021992499719386164, 0.020755426513331277, 0.01947061547213166, 0.018046018148443428, 0.016079059375373385, 0.013828215133130702, 0.01155407153427478, 0.009485088569492053, 0.007885840151126531, 0.007086851569763236, 0.007042900138221511, 0.007422950136765589, 0.008251336823920133, 0.008910531875838809, 0.009374912049053974, 0.009186340944538579, 0.00883806519587026, 0.008251168091893635], [0.4682459116304952, 0.4092597345241481, 0.39361138032104304, 0.37141745064572357, 0.3440087437706973, 0.3251507903900673, 0.31917799512534334, 0.31925361672961705, 0.3204720953882585, 0.31671180065938226, 0.31641047084746693, 0.3164268719453317, 0.3043957265145605, 0.29407062478932927, 0.2892275126404233, 0.27770587064887486, 0.27558033609644145, 0.26792973339196474, 0.26509625605066767, 0.26542904619608443, 0.25561196945942494, 0.2556812289384498, 0.25559816955306486, 0.2576597648785705, 0.26386397196506745, 0.26482400514115095, 0.27293013945188127, 0.2759549043497026, 0.28308622118359633, 0.2876670472114173, 0.29693602211353126, 0.3008370521396897, 0.30637672813753464, 0.30672380897747115, 0.3045699708243207, 0.302334684449776, 0.3014776402762645, 0.29625833369178645, 0.30153505657943236, 0.29336523082941446, 0.2834129387873466, 0.26461662317260476, 0.24991624864415973, 0.23003558587240158, 0.22614353503757822, 0.22307636821852905, 0.21665580439214463, 0.23371052231639167, 0.2508015401010173, 0.1837323145482765, 0.13179295055462414, 0.10301295762541977, 0.10404029292778172, 0.1309135353943589, 0.15687624396896951, 0.17675130304339057, 0.16802863713979843, 0.1492099406093722, 0.09193750098955339, 0.06392985124672124, 0.062369767234470956, 0.07360763875354095, 0.07689149573185625, 0.06836570035256419, 0.059690375264591276, 0.05716490398512187, 0.055752151388505526, 0.05415337471678147, 0.05317111746253912, 0.05164187157826135, 0.049794904809209645, 0.04786316492665505, 0.046300902388271434, 0.04459392368561182, 0.04295639164451792, 0.04103589302489371, 0.03814550103322199, 0.03509624777933293, 0.03177572500119598, 0.028414685544514585, 0.02542603558701701, 0.023317484851216132, 0.021900768095555093, 0.02088854595519237, 0.01942145519577199, 0.018056400414710818, 0.016709758701134607, 0.014850545661272956, 0.012878971386254002, 0.010825559213448027, 0.008977686884773843, 0.0075058355678627045, 0.006690790796511096, 0.006518758979182843, 0.006661040427978543, 0.007185462407654322, 0.007616930466919683, 0.007911909469440275, 0.007714039714635473, 0.0073301787728383, 0.006802197377907591], [0.4050289148851131, 0.3494472262690025, 0.33462775793037997, 0.3116669414509049, 0.28231692271559217, 0.26320921827856997, 0.2595001456851641, 0.2631523605376574, 0.2679280734300398, 0.26663484531264037, 0.26899248030174366, 0.2719406946976377, 0.2604893915858713, 0.2510131355660686, 0.24797362295160205, 0.23685894367312998, 0.2372525439934531, 0.23025626315658693, 0.2295357557560261, 0.23207839687920073, 0.22297694769917586, 0.2248686924008864, 0.2269570545636955, 0.23136649025533734, 0.2405531795957563, 0.2439428097485904, 0.25448041249328507, 0.2595437804816993, 0.2688979973455062, 0.27494088982677845, 0.2860406748734425, 0.29064650106703793, 0.2969313183185624, 0.297625982823509, 0.29595204213806975, 0.29352233468818517, 0.2930094883853891, 0.28812844968192275, 0.2931678702351687, 0.28463501670322405, 0.2744620700329267, 0.25494778341546065, 0.23955060112287704, 0.2190578116648361, 0.21548950904981937, 0.21271848333347554, 0.20669154063690293, 0.22326248936533616, 0.23826958925115474, 0.17178011410873784, 0.11939216955831736, 0.09215521319217923, 0.0963279556871795, 0.12569542341920426, 0.15274908698962603, 0.17184749075731598, 0.16215356175796233, 0.14276047994111904, 0.08760196956095764, 0.060635710946349945, 0.059730542275204336, 0.06975883333666895, 0.07241205181177586, 0.06485036359652524, 0.057363508836271115, 0.05513461598645516, 0.05384382269499738, 0.05230015042999059, 0.0515031002259411, 0.05020408320761057, 0.048599895367990066, 0.04690951151335136, 0.04548533368380525, 0.04387188610986417, 0.042255470441337525, 0.04041024003607164, 0.037555119421251205, 0.03455107519352591, 0.031249136765018597, 0.027893651121070125, 0.024903247876063375, 0.0227557487508478, 0.021240632188230833, 0.02013600269261889, 0.018611724183609728, 0.017232195204844675, 0.015918865187969086, 0.014127661752514604, 0.012285851697912709, 0.010361238893638982, 0.008637660646044073, 0.007264097379060912, 0.006478271753603568, 0.006284524393540292, 0.00636113764919244, 0.006785099028370986, 0.0071394670765883754, 0.007366213412822453, 0.007154373128368074, 0.006755970217334286, 0.006242891172068034], [0.3686212930806277, 0.3197860910066233, 0.3060860437046341, 0.2835909419596513, 0.2548018048466455, 0.23712066301800483, 0.23546753825174144, 0.24152704944196887, 0.24845407755674778, 0.2489448450767786, 0.25266606475078174, 0.2571579608186509, 0.24652271728141442, 0.2377541926284539, 0.23550806433902233, 0.22469597772439895, 0.226142114666909, 0.21914493228620122, 0.21914921957828953, 0.22213983709101762, 0.21313803342400456, 0.2152273295872737, 0.2177368485337965, 0.22261060177209382, 0.2324567965538607, 0.23650795903434965, 0.24745683267317903, 0.2529259420948379, 0.26262291818122313, 0.2687994336677848, 0.28023323144586443, 0.2845668212394905, 0.29066218703308433, 0.2911858677429272, 0.28958707110460247, 0.28696418201943613, 0.28667511368036624, 0.28208405123540475, 0.2867681616141134, 0.2780646120907348, 0.26786355456565125, 0.24825293195563303, 0.2327115523649921, 0.21225242367527322, 0.2089504489778365, 0.2065857769846928, 0.20102316121515318, 0.21691633279529401, 0.23030458989461147, 0.1656117973068181, 0.11436038745381714, 0.08823634589806915, 0.093268958649211, 0.12283397558699681, 0.1497797895041603, 0.1682485161165335, 0.15807626644658743, 0.13882784883185242, 0.08557420068858976, 0.058961764069496214, 0.05802738404145873, 0.06715201653566485, 0.06951597939628947, 0.06252242088176489, 0.05565583573538467, 0.05358460552224723, 0.05235971204607901, 0.05087036478233776, 0.05015063626482378, 0.048942113241711126, 0.04744072239526029, 0.045853490369515235, 0.0444904027531563, 0.042922634529657944, 0.041313934064562574, 0.039529876108328026, 0.03674159206476699, 0.033806183343900766, 0.030555958041091166, 0.02725147047191559, 0.0243067645491206, 0.02217656112510982, 0.020635573513863123, 0.019499425716659177, 0.01797400509645359, 0.016602981015596072, 0.015312846437958444, 0.013578035418989621, 0.011818624293207809, 0.00999014226188775, 0.008356744192610214, 0.007064333706200187, 0.006313782157626492, 0.0061212289023685335, 0.006175957132835933, 0.0065586441135955945, 0.0068803065769884, 0.0070781338370115784, 0.006860129467598502, 0.006462571564041299, 0.005959860502202254], [0.3435703049293157, 0.3019115260482023, 0.2893544384051805, 0.267819044896732, 0.2406271595083824, 0.2249798918510301, 0.2250494921520502, 0.2327281190936211, 0.24095707083883527, 0.24273637192536773, 0.2471541893000158, 0.25245730578426784, 0.24257404981425643, 0.2343576097693222, 0.2324238895785142, 0.22184654674654833, 0.22369105822987803, 0.21653312677501582, 0.21673324099516234, 0.21961932565796646, 0.2106077903043246, 0.21246729161429243, 0.21486135054308492, 0.2196091436628302, 0.22936811653182126, 0.23349660003875272, 0.24424834259820968, 0.2496059381794925, 0.2590819313123175, 0.2650111254061268, 0.2763187256633946, 0.28019459685616305, 0.28590764650831835, 0.28614933423152533, 0.28448980094277687, 0.2817263519248784, 0.2815826026923126, 0.277212569153846, 0.28156538128329744, 0.2728037166723556, 0.2626854703040513, 0.24327242184031175, 0.22785845984498374, 0.2076674949439018, 0.20449345695211904, 0.20243519861360218, 0.1971717161268785, 0.212550126457318, 0.2249047882613708, 0.1621830392301812, 0.11237380159663483, 0.0869814965900532, 0.09188031502334307, 0.12087220389928052, 0.1473120858701298, 0.16526372916734716, 0.15487169697298506, 0.13593699956180938, 0.08419316024839642, 0.05782339757552531, 0.05672722654991821, 0.06520276842717965, 0.06740905415449351, 0.060762066136615986, 0.05426531174220626, 0.0522988621597888, 0.0511209286776591, 0.04968085445284004, 0.049004208554943106, 0.04784285287576371, 0.04639935906458627, 0.04486961907641928, 0.043543828346667236, 0.04200633621054027, 0.04040459934843496, 0.038672228460127384, 0.03595150770609543, 0.03308343420911122, 0.02988848009484986, 0.026640815402500975, 0.023747275666157475, 0.021645269074404627, 0.020099153186499127, 0.018950334111302203, 0.01743795348030623, 0.016081220821427794, 0.014810963683033829, 0.013125405251632773, 0.011429984791204092, 0.0096804259553018, 0.00811986523748538, 0.006894810987406653, 0.006176301774057338, 0.005989331814548227, 0.006034005889223508, 0.006393002501536415, 0.006695117439476045, 0.0068763379426275235, 0.006655198191837257, 0.006262780424337408, 0.0057693153183559125], [0.324100685684476, 0.2891239334308429, 0.27759207957665394, 0.2571124683076975, 0.23176839988395415, 0.21818667356067975, 0.21965533607078436, 0.2284791524461619, 0.23755472268991273, 0.2402957552841436, 0.2450934687999522, 0.250868470642519, 0.24160099074903904, 0.2338068796284753, 0.23199084245530988, 0.22158708804667232, 0.22358666543258177, 0.21624991783348615, 0.21647416898988714, 0.21912681426073208, 0.21008894206499945, 0.21164933861618657, 0.21380762643689175, 0.21829728557006708, 0.22778421849023367, 0.2318368666434666, 0.24225983879518626, 0.24738702712744787, 0.2565228074922212, 0.2621376039631657, 0.2732159819829379, 0.27664007743317987, 0.28197732354683197, 0.28194806500332703, 0.28019756814498537, 0.27733598304545093, 0.2773026575564857, 0.27311596158036017, 0.27718123723496235, 0.26841181466684216, 0.25841292104433494, 0.23927949281559072, 0.22407452669369315, 0.2042040337751992, 0.20109511380281048, 0.19926451222983893, 0.19419478770494703, 0.2091638532570777, 0.22076576947669416, 0.15983272857336403, 0.11135578670308223, 0.0864925019713643, 0.09102414895573488, 0.11931182506311538, 0.1451871122209805, 0.16269875000479272, 0.15218802422036914, 0.13358505276762175, 0.08307492497692913, 0.0569185194113583, 0.055651689184157194, 0.0636228842873332, 0.06572296786339814, 0.05932382804927989, 0.053090785324822025, 0.05120390648119779, 0.05006313005904391, 0.04866468240199096, 0.048017048074069785, 0.04688729058305188, 0.04548502036734709, 0.043995707916885306, 0.04269767483382333, 0.04118440460206565, 0.03959044424301758, 0.037902097897745686, 0.03524252618169113, 0.032435409983179654, 0.029292443073454952, 0.02609813782815141, 0.02325188459463252, 0.021178344197438814, 0.01963433795464539, 0.018480340809508857, 0.016984131382373577, 0.015642643458816077, 0.014390099576219503, 0.012747359484065576, 0.011104696739697086, 0.009420954519612274, 0.007920586347609827, 0.006751045556824413, 0.006059797735458406, 0.005878674792690071, 0.005917429942168796, 0.006259649997294701, 0.00654748913382773, 0.0067168542855070845, 0.0064937761136223526, 0.0061072038649084255, 0.005622008524235474], [0.3080928799549733, 0.27913653161180296, 0.2684877766042166, 0.2490288407074356, 0.22551165769488066, 0.2138464511774847, 0.2164467519144769, 0.22611100018383384, 0.23576422235126698, 0.23924113960701385, 0.244251532811684, 0.25032192454193325, 0.24154761832991575, 0.23407998306105762, 0.232297866887615, 0.22202473617290172, 0.22408116899541375, 0.2165818833404041, 0.21677305481012968, 0.21917836677979702, 0.21011410481863788, 0.21139184790207566, 0.2133065345587025, 0.21753115888423616, 0.22671929494687554, 0.2306639340424005, 0.24075409902212003, 0.2456415881048372, 0.2544367600370168, 0.2597510922539026, 0.2705944664752274, 0.2736121087490071, 0.27862070887171475, 0.27835686666662823, 0.27651675929797104, 0.2735867432805186, 0.27364511597058044, 0.2696165186941899, 0.27343365035154743, 0.264677837256246, 0.2548048800992503, 0.23595478542334172, 0.22096910741918976, 0.20140964349386412, 0.1983410880856751, 0.19668968568578507, 0.191756944955972, 0.20638243542861898, 0.21738419889566515, 0.15799789125086283, 0.11067247005855292, 0.08622042765539695, 0.09037194865597735, 0.11799188026287102, 0.14333688771706146, 0.16046931575984827, 0.14988509893612312, 0.13159516316025133, 0.08211706170889056, 0.05615200689892428, 0.05473073526029465, 0.06228936152911101, 0.06430861438700819, 0.05810721477256868, 0.05208308633252786, 0.05026102681037204, 0.049151050543216036, 0.04778731966772421, 0.04716096989418559, 0.04605504700065139, 0.04468525113430589, 0.04322730409216416, 0.041951625875558875, 0.040459061855575976, 0.03887333612559145, 0.03722284610156589, 0.03461739606494561, 0.03186448007253367, 0.02876891494730109, 0.025622872311444892, 0.022818770358772878, 0.020771744192741436, 0.019233034389752646, 0.018077763334908382, 0.016597899811576177, 0.015271268567796481, 0.014034733287528247, 0.012429080571805636, 0.010830789177966304, 0.009202173478183, 0.007751997432623292, 0.0066282432071748075, 0.00595989470133045, 0.005784030464851383, 0.005818815821722998, 0.006148011240430694, 0.00642455992403739, 0.0065846168348754055, 0.006360226975055845, 0.0059792488327802835, 0.0055014190295740485], [0.2945878035683225, 0.2710183791358404, 0.26112306469755964, 0.2426138040244814, 0.2208185609791818, 0.21088163475410276, 0.21440052634056417, 0.22469412617217363, 0.23474962280991515, 0.23879861301246402, 0.24392254148244555, 0.25018271296003874, 0.2418029182423022, 0.23459024202614376, 0.2328002490566611, 0.2226268405723902, 0.22469316357339775, 0.2170530744366893, 0.21719068958672239, 0.21936451750126576, 0.21027704213285212, 0.21130594590083465, 0.2129969728325845, 0.21698049053352517, 0.2258855482848706, 0.22972270793302688, 0.23950737191493576, 0.2441736506624634, 0.25265688755214705, 0.2577022148193371, 0.2683293701431489, 0.2709903953995409, 0.275720261581078, 0.2752588366453891, 0.27333833638234484, 0.2703609854332256, 0.2704980452378741, 0.2666074197641993, 0.2702096700258028, 0.2614764205395753, 0.2517249257077205, 0.23313870002557294, 0.21836047668442998, 0.19908611877807586, 0.19604745495989123, 0.1945422549844506, 0.18971235232054273, 0.20404284223084276, 0.21454730563575447, 0.15648244079463489, 0.11013908785687915, 0.08601848230708006, 0.08982543581022628, 0.11684690138364326, 0.14171538046330653, 0.15851947719133527, 0.14788657489092097, 0.1298826485253849, 0.08127971589811236, 0.055485833205710426, 0.05393046131085715, 0.06114340509022127, 0.06309743544418547, 0.05706132532741323, 0.051210044961801, 0.049442040821878065, 0.04835800981934159, 0.04702328698558715, 0.04641310924402831, 0.04532604376668343, 0.043982874191377336, 0.04255025310351, 0.04129318206598697, 0.039818779545651745, 0.03824140817955804, 0.03662380569000036, 0.03406621748642083, 0.03136141753195216, 0.02830882166709497, 0.025206165292054834, 0.022439551330767055, 0.020416859811344182, 0.018885114375311787, 0.017730984097909568, 0.016266797250562685, 0.01495427051816927, 0.013732282603341505, 0.012158838273474354, 0.010598221795990206, 0.00901603585392062, 0.007607988831259497, 0.006522260351283631, 0.005873184737066034, 0.005701938510806943, 0.005733934189779955, 0.006052648424630192, 0.006319999855126899, 0.0064724473264149, 0.006247179351375039, 0.005871343389192687, 0.005400049954273799], [0.283030633353332, 0.26428245606932527, 0.255030016913605, 0.237392726820203, 0.21719143625786871, 0.20879812169224876, 0.21306684135606363, 0.22383715061905105, 0.23417384143805464, 0.23867254284748357, 0.24384707576618683, 0.25022799100379445, 0.24216481887956337, 0.23515249915853426, 0.23333146128442842, 0.22323458471932006, 0.2252849940347742, 0.21752430138130546, 0.21760098904586087, 0.21956568646615462, 0.21045851136868227, 0.21127264861877548, 0.2127651983926801, 0.2165369237215064, 0.2251851522851529, 0.22892392885704596, 0.23843611643261892, 0.24290533468212222, 0.25111042055484345, 0.2559193725802214, 0.26635393653459194, 0.2687044685691148, 0.27319993904647366, 0.27257329316431517, 0.27058277871554176, 0.26757355611098843, 0.2677787170392151, 0.2640089568747102, 0.2674242277576493, 0.2587169693675576, 0.2490784007996033, 0.23073100085686354, 0.21614241425796762, 0.19712483020655705, 0.1941113598184982, 0.19272777767920132, 0.18797800883156826, 0.20205242152057767, 0.21213748927719905, 0.1551990071374334, 0.10969303662398831, 0.08584437179000398, 0.08934837213019305, 0.11584064846866737, 0.1402863426700107, 0.15680529258886067, 0.14613946007635495, 0.12839417797715486, 0.08054055213548662, 0.05489951263820927, 0.05322941379544569, 0.060149280768642246, 0.06204913148518897, 0.05615357256935462, 0.050447719871473756, 0.04872501724795546, 0.047662851666849866, 0.046352493406025375, 0.045754812578055276, 0.044683014338266276, 0.04336207596762859, 0.04195031617188121, 0.04070903344425686, 0.0392507657943368, 0.03768162374231401, 0.03609284258360657, 0.03357781527554806, 0.030915937891891822, 0.027902335962987704, 0.02483876984813503, 0.02210570478887678, 0.020105287646834797, 0.01858146969844434, 0.01743008410882591, 0.01598069712888629, 0.014681443671180504, 0.013472727165154434, 0.011927351086357561, 0.010398995257091204, 0.008856134260504722, 0.007483740921921199, 0.00642981644512684, 0.005797082485734755, 0.005629903301056491, 0.005659959199173986, 0.005970105479185204, 0.00622988763114236, 0.006376025886513458, 0.006150216142313985, 0.005779043474140271, 0.005313558302767631], [0.27304401952937385, 0.2586209113375962, 0.2499188375346396, 0.23307831332873932, 0.21434111573853912, 0.207322827293701, 0.21220746530171763, 0.22334144573840675, 0.23387326906866857, 0.23872860270753946, 0.24391235118571394, 0.25036669678297474, 0.24255872580354748, 0.23570435126020128, 0.23383874403828878, 0.22380054316144532, 0.22581967905424083, 0.21795566068383068, 0.21796933727521353, 0.21974716134827207, 0.21062331539086626, 0.21125302446288888, 0.21257117255076796, 0.21615895255100515, 0.22457749414525321, 0.22822863683061342, 0.23749993575594672, 0.2417957734357223, 0.24975479198900974, 0.25435711798913063, 0.2646219564963328, 0.26670261089806674, 0.27100127849228156, 0.27023667482617386, 0.2681857288554559, 0.26515616840211975, 0.2654203873366339, 0.26175664440146307, 0.2650083857529525, 0.2563278959602278, 0.2467924471928527, 0.2286590286028495, 0.2142415121638541, 0.195454070035353, 0.19246378661550223, 0.19118268903007635, 0.18649688765984257, 0.2003473945796245, 0.21007507877975687, 0.15409747074427363, 0.10930791925997528, 0.08568466815757993, 0.08892362487428325, 0.11494859786208157, 0.13902024743896707, 0.15529084549750635, 0.14460289806265067, 0.1270909626781284, 0.07988392684087188, 0.05437948503558636, 0.05261163702694151, 0.0592813011231269, 0.06113537127192107, 0.05536012550133536, 0.04977738334453114, 0.048092604363249684, 0.04704888265312657, 0.04575909427581399, 0.0451710964007132, 0.04411179506430654, 0.04280963748794435, 0.041415279260342185, 0.0401875724004932, 0.03874374908293179, 0.03718258916596415, 0.035619310998297425, 0.033142374717036974, 0.03051895941902355, 0.02754087907152298, 0.024512698137914228, 0.021809856858430336, 0.019829915665691752, 0.01831457961161595, 0.017167033810487745, 0.015731544152771004, 0.01444472779487383, 0.013248170682717575, 0.01172737386970867, 0.010226837011416008, 0.008717504470634263, 0.007375496573180429, 0.00634841747686356, 0.005729693088190917, 0.00556612120983551, 0.00559487577014907, 0.005897974361935183, 0.00615153143569659, 0.006292408384455414, 0.006066302440707915, 0.005699354692704774, 0.005239050228172152], [0.26434856158236103, 0.253817098906904, 0.24558825932432973, 0.22947471277336046, 0.21207785561055362, 0.20628484171321257, 0.21167868624452746, 0.22309143651618302, 0.23375617191151626, 0.2388963680274611, 0.24406178837439899, 0.25055621490845403, 0.24295474256911528, 0.2362251236569511, 0.23430699646607472, 0.2243134187588639, 0.22629176149264923, 0.21833887715339387, 0.21828984438593607, 0.2199010044260379, 0.21076291620670592, 0.21123415715923582, 0.2123993491690395, 0.21582773130440394, 0.22404181846077398, 0.22761563338447655, 0.23667435670005998, 0.24081810709686505, 0.24855975881479547, 0.25298147218405453, 0.2630972401950643, 0.26494306206901497, 0.2690763970041686, 0.26819644818116034, 0.2660934680048461, 0.26305228907765976, 0.2633677384743786, 0.2597971257629353, 0.2629050362099133, 0.2542508066681269, 0.2448086746492247, 0.22686631443247215, 0.21260244863983377, 0.1940213105067898, 0.1910535453589886, 0.1898596184859958, 0.1852258520021802, 0.19887939858325268, 0.2083001751331568, 0.15314378706230636, 0.10896992809213077, 0.08553472814802696, 0.08854119962727679, 0.11415244604092513, 0.13789283314114925, 0.1539464815918904, 0.14324418164824415, 0.12594295205206338, 0.0792976809001737, 0.053915520912605513, 0.052064434013067616, 0.05851941957570207, 0.06033437611394858, 0.05466241986345046, 0.049184200888997234, 0.04753104107572084, 0.04650285602280626, 0.04523051239264935, 0.044650051228418836, 0.04360101817348623, 0.04231484455355207, 0.040935145061747315, 0.03971922285533398, 0.03828843856339453, 0.036734941406960354, 0.035194383232211295, 0.03275174539176671, 0.030163007661481403, 0.02721740991952845, 0.024221428930233914, 0.02154600260181035, 0.01958495612810995, 0.018078370614982162, 0.016935436011310902, 0.015512946895414857, 0.014237780859063227, 0.013052381831122341, 0.011553243821391281, 0.010076830199324824, 0.008596278548660146, 0.00728037650569789, 0.006276132821610681, 0.00566950608355989, 0.00550919586658925, 0.0055371556521994336, 0.00583446189807894, 0.006082859364673514, 0.006219348803417116, 0.005993151019960955, 0.00563003295456854, 0.005174349608002727], [0.256728093418144, 0.2497094141711332, 0.24188939523839653, 0.22643925130405826, 0.21026807697016842, 0.20556884631031963, 0.2113864987884509, 0.22301353351886263, 0.23376576586437503, 0.23913484380352582, 0.24426357543504734, 0.25077432296257895, 0.24334043696722701, 0.23670927023115107, 0.23473417810780084, 0.22477413015226902, 0.22670573252881113, 0.21867605012579092, 0.21856567098208673, 0.22002797800393328, 0.2108775763621435, 0.21121224940996117, 0.21224306965456333, 0.2155332111184947, 0.22356534951712212, 0.2270710236203897, 0.23594190423563263, 0.23995232337313857, 0.24750168503592396, 0.25176519934216546, 0.2617500203257374, 0.26339112720803864, 0.26738524107799155, 0.26640874221627514, 0.26426094118668314, 0.2612147353011918, 0.2615745662589694, 0.25808589532483467, 0.2610666578130583, 0.2524375715742831, 0.2430794857358452, 0.22530770392009988, 0.21118168256590356, 0.192785896071753, 0.1898406165805491, 0.1887214912225183, 0.18413064776495763, 0.19761000624328676, 0.20676550398967647, 0.1523126065302234, 0.10867037230895908, 0.08539285471351529, 0.0881943388895443, 0.11343783054179592, 0.13688412362753952, 0.1527476191728338, 0.14203670322456544, 0.12492614913973922, 0.07877195786498864, 0.0534995321145205, 0.05157744952400546, 0.05784748628056119, 0.059628705499185274, 0.0540455704791942, 0.048656212890940104, 0.04702933002092715, 0.0460141603310697, 0.044756698202031944, 0.04418207332856313, 0.043141537395557455, 0.04186904906051104, 0.04050179103549059, 0.03929618378220158, 0.03787722855157151, 0.03633103366169957, 0.03481087890004314, 0.0323992853452556, 0.029841992428421837, 0.026926217421336145, 0.023959664675588462, 0.021309271876815195, 0.019365705156538692, 0.017867981190876302, 0.01673015836479572, 0.015319826430937652, 0.014055573563004853, 0.012880462092787866, 0.011400496263252636, 0.009945154805241432, 0.00848945906880665, 0.0071961151906624705, 0.00621146236956356, 0.005615391981575407, 0.005458044590214777, 0.0054856239202921995, 0.005778154928167066, 0.006022313130697305, 0.006155124663958605, 0.005928998999368539, 0.005569369943841883, 0.005117818490607787], [0.2500111708951069, 0.24617344196445964, 0.2387082643976759, 0.2238640553559362, 0.20881381973654392, 0.2050935711076116, 0.21126616461438266, 0.2230581520844467, 0.23386445994969118, 0.23941837029139654, 0.2444983667400611, 0.2510083060454553, 0.2437108359405927, 0.2371571360343862, 0.235122849488202, 0.22518747855430568, 0.22706872079225865, 0.21897226188303687, 0.21880243535476898, 0.22013143825268291, 0.2109702074527269, 0.2111867746812827, 0.21209916190491748, 0.21526914061002583, 0.22313905164013026, 0.2265846607074926, 0.23528914660747544, 0.2391824309551326, 0.24656124834553447, 0.2506858043448608, 0.26055537770969694, 0.2620175702791182, 0.26589419861040453, 0.2648367966476848, 0.2626502745240137, 0.2596040484730405, 0.2600023468641251, 0.25658587481453354, 0.2594536807652666, 0.2508483382517369, 0.2415658157236354, 0.22394653035031986, 0.2099442681741802, 0.19171551190778832, 0.1887930077708682, 0.18773853647977348, 0.18318354322663646, 0.1965080928025751, 0.20543294967066353, 0.15158414095293032, 0.1084031194758773, 0.08525828646104956, 0.08787803282689582, 0.11279320937680949, 0.13597753366668372, 0.1516738447474122, 0.14095859044969836, 0.12402102840442716, 0.07829860038504484, 0.05312492178900014, 0.05114216025919997, 0.057252251990214845, 0.05900414863559411, 0.05349748387363061, 0.04818375389382399, 0.04657855884252011, 0.04557430514806332, 0.044329590306915065, 0.04375944542671317, 0.04272595827727647, 0.04146526049755316, 0.040108612252577926, 0.038912090974013804, 0.03750391594237856, 0.03596465767441312, 0.0344629272666696, 0.03207961412412381, 0.029550944774049386, 0.026662647756358366, 0.02372312682165368, 0.021095691669651, 0.01916836126600281, 0.0176794843166872, 0.016547089232331638, 0.015148153928346512, 0.013894119318396242, 0.012728489319284254, 0.011265589066383584, 0.00982874545251145, 0.008394664678729048, 0.007120956437134522, 0.006153231667737663, 0.005566429409879001, 0.005411827424372125, 0.005439358552704787, 0.0057279668335213875, 0.005968631949940921, 0.006098373830054034, 0.005872435924823639, 0.005515988210585796, 0.005068152036244232], [0.24405965415906805, 0.24311137631153293, 0.23595560221012568, 0.22166558291877525, 0.2076414007989725, 0.20479997676844983, 0.21127176029495598, 0.22319061699697684, 0.23402631599139886, 0.2397301520823027, 0.24475366562342676, 0.25125050135200844, 0.24406419607177499, 0.23757115452649863, 0.23547694118376367, 0.22555911213408375, 0.22738797075239348, 0.21923311922941455, 0.21900600832734712, 0.2202151459344732, 0.21104428314975499, 0.21115828297385542, 0.21196587989031654, 0.21503108864191098, 0.22275602602040245, 0.22614849441805987, 0.23470512027493806, 0.2384952787015563, 0.24572231998567667, 0.249724443518595, 0.2594923532323263, 0.2607977286895129, 0.2645750696434416, 0.2634497138023907, 0.2612296318857563, 0.25818726537343617, 0.2586188564903451, 0.2552661465801578, 0.2580330874117439, 0.24945002323412058, 0.24023538599057168, 0.2227526853468494, 0.20886177203949888, 0.19078404406426488, 0.18788468128125166, 0.1868865069895781, 0.18236180342784486, 0.19554806753368584, 0.20427136414890987, 0.1509425705506516, 0.1081634711600264, 0.08513066674375153, 0.08758831133615981, 0.11220911668544123, 0.13515926808490797, 0.15070808938370675, 0.1399917369778155, 0.12321161560918471, 0.07787076554533975, 0.05278622557226629, 0.050751450719477884, 0.05672274936417802, 0.058448999656148366, 0.05300820606210717, 0.04775885172774083, 0.046171504354296615, 0.045176371736846105, 0.04394261716095697, 0.04337585403589204, 0.04234823216653121, 0.041097707419451, 0.03975019323449594, 0.038561715306524635, 0.03716342673190644, 0.03563073539718616, 0.03414573412131844, 0.031788295141385946, 0.029285808956741582, 0.026422918712285172, 0.02350828996947863, 0.020902025655028328, 0.018989815488393888, 0.01750968225962109, 0.016382900638365148, 0.014994629299657272, 0.013750186156909908, 0.01259333225145882, 0.011145695883457006, 0.009725186653354785, 0.008309994253561152, 0.007053478011317512, 0.006100497855555761, 0.005521907446947837, 0.005369842120001293, 0.005397580453833069, 0.0056829802469704664, 0.005920800163542712, 0.006047965997242854, 0.005822306731913801, 0.005468773093122232, 0.005024284737040094], [0.2387609335472397, 0.2404452814088712, 0.2335604738459957, 0.21977821428913516, 0.2066944400641872, 0.20464445605389384, 0.21136993659069203, 0.22338608876711097, 0.23423295573294756, 0.2400587542929161, 0.2450211011370771, 0.2514959436091391, 0.2444003074022468, 0.23795435412222055, 0.23580045374475397, 0.22589445500872746, 0.22766998882830095, 0.21946379359835716, 0.21918163042733882, 0.22028261027679277, 0.21110301882290977, 0.21112758078749377, 0.21184210145509286, 0.2148156533862755, 0.22241061436012585, 0.22575597472582576, 0.23418075095073307, 0.23787986650625453, 0.24497137843369163, 0.2488652851979403, 0.25854324432185183, 0.2597107584596083, 0.26340399738437487, 0.2622215576256836, 0.2599723497951819, 0.2569366710848619, 0.25739713180892765, 0.2541008296499372, 0.2567773041434646, 0.2482150633679579, 0.23906146716966234, 0.22170141749020564, 0.20791089203412763, 0.18997022000930358, 0.18709434272405506, 0.18614550269675595, 0.1816466611476254, 0.19470885004397306, 0.20325513204995124, 0.150374969983665, 0.10794765790468258, 0.08500965814687625, 0.08732197781021826, 0.11167767907179095, 0.13441779660716283, 0.14983607146029598, 0.13912107446828406, 0.12248467881166582, 0.0774827034215415, 0.052478846748105316, 0.05039937589716723, 0.05624984060763637, 0.05795352029214004, 0.05256953474253306, 0.04737500209125766, 0.045802202869813305, 0.04481466131351209, 0.043590386048592396, 0.04302613020719432, 0.042003379290292374, 0.04076170158820471, 0.03942205700448117, 0.038240758795309755, 0.03685153121919178, 0.03532506885204824, 0.033855331615557184, 0.031521647712180294, 0.029043216554029482, 0.026203892467972344, 0.023312293286084, 0.020725609276352454, 0.018827514122221015, 0.017355960708460332, 0.0162348859457725, 0.014856621920708987, 0.013621164024068405, 0.01247246731940464, 0.011038545394221506, 0.009632526763088274, 0.008233937750648802, 0.0069925671322398795, 0.006052492308978954, 0.005481219039490608, 0.0053315370722917844, 0.005359705516423484, 0.005642475616016406, 0.005877977800292721, 0.006002995877834252, 0.005777699682655181, 0.005426834849631054, 0.004985364803247551], [0.23402235881339167, 0.23811234908928344, 0.23146584480325227, 0.21814961150847895, 0.2059291180129777, 0.20459420655267935, 0.21153610581193666, 0.22362644209415145, 0.23447096671799758, 0.24039624892829678, 0.24529484655835307, 0.2517414400516886, 0.24471970038016197, 0.2383098362815006, 0.23609713888626754, 0.22619834588251575, 0.2279203484272715, 0.21966875900598926, 0.21933378070406362, 0.22033679153216443, 0.2111492152442637, 0.21109548809946121, 0.21172700630143187, 0.21462006660151414, 0.22209817812203225, 0.22540159574138507, 0.23370839405058758, 0.23732690233136808, 0.24429696937709422, 0.2480948646283666, 0.2576930363345886, 0.25873902448441616, 0.26236092012192086, 0.26113049703934577, 0.2588558832083969, 0.2558291159508387, 0.25631457860683077, 0.2530682922548534, 0.25566326074667184, 0.24712044869323002, 0.23802176915623002, 0.22077214917746418, 0.2070723797971237, 0.18925647473832807, 0.18640439138432735, 0.1854990546300123, 0.18102249269251972, 0.19397290896886032, 0.20236300147388794, 0.14987076341837274, 0.10775261344166122, 0.08489500036414235, 0.08707635953334697, 0.11119236576469267, 0.13374339477019076, 0.1490457656747108, 0.13833398436914887, 0.12182919970055925, 0.07712952412462122, 0.052198939010387066, 0.05008092340503486, 0.05582588642271838, 0.05750960338736022, 0.0521746339562813, 0.047026775136308874, 0.045465740725208974, 0.04448449755760444, 0.043268422851644686, 0.042705971896927306, 0.041687271566818285, 0.04045329166368211, 0.039120476108642874, 0.0379456023879166, 0.03656473706696564, 0.03504415509914952, 0.033588411724482146, 0.03127663880571903, 0.028820374976337063, 0.026002976306698497, 0.02313275237120044, 0.020564244327351194, 0.018679356113695568, 0.017216171749616253, 0.01610082292498281, 0.014731946896072635, 0.013504950331287442, 0.012363820773641867, 0.010942256374979278, 0.009549176004841033, 0.008165260333304218, 0.006937295731443713, 0.006008598338050408, 0.005443889294557107, 0.005296452945715055, 0.005325201314353675, 0.005605862876824607, 0.005839484700728935, 0.005962712196013848, 0.005737818444247735, 0.005389416242879595, 0.004950682408371269]]\n",
      "[0.9302450443059735, 0.9069813183594942, 0.8950565451780425, 0.8840746533431112, 0.8743595336163951, 0.8655244913726188, 0.856922558964229, 0.8485899743996339, 0.8398948319403262, 0.8309498837335527, 0.821133519683297, 0.810829310897514, 0.7990789370288055, 0.786637135174792, 0.773834749175389, 0.759916514775445, 0.7472096204417576, 0.7332194949325487, 0.7197749971603593, 0.7059715347396728, 0.6898989891226106, 0.6750486783805574, 0.6588363336335504, 0.6434937773604864, 0.6269224757506783, 0.6094565793936777, 0.5929058582332037, 0.575419458391751, 0.5578804787035574, 0.5397063887832478, 0.5247074879526371, 0.506290992208222, 0.49015277244200767, 0.47219634278706135, 0.45579836429086645, 0.4409519939236635, 0.42821514966885865, 0.4155128909416621, 0.4071794032436354, 0.39378714404165155, 0.38123632374919664, 0.36343583580843125, 0.3479937007774462, 0.33131177633926406, 0.32378981556120456, 0.31652293193877684, 0.30710494674202504, 0.3147636026247451, 0.3186779861057221, 0.2685306710781816, 0.22494853350779315, 0.19554420874169526, 0.19471848922581558, 0.21232012358470134, 0.22863176266620813, 0.24159733858811025, 0.23040085404863445, 0.2142576343605193, 0.1626220318462785, 0.12321115345883374, 0.11592588870755044, 0.12029409194057333, 0.119845006958211, 0.10811964050962461, 0.09489484801047454, 0.08959027332002278, 0.08607148769955306, 0.08329903915505356, 0.08110296775026099, 0.07820971674377325, 0.07561817246243496, 0.07306057344245291, 0.07046784020933451, 0.06835675006178835, 0.06650906232157543, 0.06463846313109325, 0.06208214994848968, 0.0592468073549775, 0.0559003031011291, 0.05149009916636938, 0.046606630206974746, 0.043460837242714385, 0.04188229005756945, 0.040857069254835884, 0.03839833838421987, 0.03639818155977338, 0.034221726275344845, 0.031204075298703136, 0.02793978405402279, 0.02420049572714993, 0.020685111205311673, 0.01738601855574927, 0.01574088502945878, 0.015622227047131293, 0.016450588001339948, 0.017953402288461724, 0.019168167957794677, 0.019862243364218185, 0.019424502617586423, 0.01868802151610637, 0.01755369310870472]\n",
      "[0.921732797490339, 0.8964251224076061, 0.8836850122342742, 0.8720756394585609, 0.8619783335514526, 0.85286437077561, 0.8439686059439556, 0.8353882888051866, 0.8264212149274259, 0.8171647748909117, 0.8070227928339708, 0.7964193903991797, 0.7842576840691886, 0.7714007541218879, 0.7582254575424174, 0.7438216227833385, 0.7307968191122924, 0.7163204545455029, 0.7024522713054414, 0.6882056798106608, 0.6715340853224209, 0.656252714501814, 0.6394565495075499, 0.6236345497708532, 0.6064638607183723, 0.588395474175228, 0.5713412252848089, 0.5534639257269458, 0.5353679714091502, 0.5169700715415796, 0.5020364275235544, 0.48350809501603015, 0.46765306527297296, 0.45013467837801346, 0.4343012783059328, 0.42037622193618585, 0.40892339246075493, 0.39754857598629023, 0.39048716594233335, 0.3779804800721778, 0.3662383389162099, 0.3490771789245212, 0.3347543541666112, 0.3191785489719334, 0.3133673854755001, 0.3074399842189407, 0.2996704175413189, 0.30838072441337955, 0.31286480366340513, 0.26248719792621217, 0.21925943122034197, 0.18867736925750628, 0.1864418559361516, 0.20236509124805138, 0.2178487860080437, 0.2310827525353688, 0.2203662883392382, 0.20560572376036804, 0.1558655034450379, 0.11767519990965218, 0.1107531546492902, 0.11585809364836362, 0.11571574069996575, 0.10381428896895321, 0.09008493325049298, 0.0843343060510353, 0.08051672106793041, 0.07769303131544537, 0.07535029110921596, 0.0722493426809371, 0.06943614206388857, 0.06658284447151501, 0.06382406811790432, 0.06168132819202296, 0.05960664289761613, 0.057983284452176515, 0.05584645037449445, 0.05335842242254676, 0.05028554959075731, 0.0462490087781181, 0.041864151524413515, 0.03925301411562791, 0.03809012687854344, 0.03742201624982201, 0.03545645940597188, 0.03377668289974679, 0.03185749392023359, 0.029117101725916972, 0.026035051174784007, 0.022463414259415553, 0.019064042698270688, 0.015738737864013103, 0.014079443765163874, 0.013956605420671741, 0.014880359295244242, 0.01646396230282876, 0.017773460349131572, 0.018489770905746446, 0.01810493522042772, 0.01746517307984759, 0.016390206134608027]\n",
      "[0.8693926098493211, 0.8361449185315821, 0.821212323083517, 0.8075310678120872, 0.7956276954252544, 0.7851682341654699, 0.7755824216047585, 0.76649495083779, 0.7572313930491856, 0.7473375487404891, 0.7366331647977218, 0.7258556400865507, 0.7127216409348133, 0.6990064753903513, 0.6853011881438962, 0.6698655670351783, 0.6565351195413885, 0.6415336969384582, 0.6274983277105687, 0.6131883138475787, 0.5958734185576801, 0.5809885098629308, 0.5644478155442438, 0.5494038354104931, 0.5330808325858823, 0.515770919854484, 0.5002614222962557, 0.4836323665211226, 0.46719862736140055, 0.45118027029310687, 0.43896523284225136, 0.42271847600850393, 0.4098990475652877, 0.3954812285012, 0.3826058962554943, 0.37341464498556826, 0.366762857819032, 0.35958810862838325, 0.3565494467225451, 0.34569547666765826, 0.3345439292034292, 0.3180766379373789, 0.30489745664388984, 0.2903219178070654, 0.28652074118893517, 0.2828704080044291, 0.27819845430474277, 0.28970908617718694, 0.2966800563716703, 0.24308821841201292, 0.20067252840650396, 0.16931296948835955, 0.16361684691704273, 0.1775122400281511, 0.19418926199343745, 0.21099130553494191, 0.20190676136076932, 0.1895851477773185, 0.14270570781923564, 0.10173782182197294, 0.0935510343327251, 0.10053074265539254, 0.10228822305160011, 0.09176990095222652, 0.07949196969107422, 0.07444632685197654, 0.07092209602805426, 0.06813261866083647, 0.06555181976831226, 0.06196693843011292, 0.05847088248090621, 0.05450049945289299, 0.05133788614464505, 0.04890738853743833, 0.04662996333448385, 0.04510519913162455, 0.04294185045178431, 0.04068659307308093, 0.03786467401182561, 0.034782946606627334, 0.0317371226124791, 0.030010952414382917, 0.029429514565903953, 0.029079857252376867, 0.02778295281051676, 0.026414788950076873, 0.024592928669371145, 0.022157074445007887, 0.019292365230393214, 0.01639124289744228, 0.013770454136957141, 0.011695346985896495, 0.010943615175391871, 0.011504753683886383, 0.012941222296322228, 0.014841496312084392, 0.01635616391671623, 0.017142683794460732, 0.016732666888499427, 0.016268354041725844, 0.015218267463462996]\n",
      "[0.7436435773617364, 0.6990995240456741, 0.6830453010746924, 0.666471706852803, 0.6503644189293416, 0.6374012975000518, 0.6280582812755956, 0.6203237593443701, 0.6129387364594203, 0.603816163829104, 0.5949540600342957, 0.5862138833482377, 0.5729308419989466, 0.5595439554195104, 0.5474017750368786, 0.5325205476210949, 0.5210044465246465, 0.5075657017974144, 0.4955696338357665, 0.4842335766366648, 0.46843214919630244, 0.45695767760010964, 0.444302793325185, 0.43335031969734844, 0.422623898429582, 0.4101200557501346, 0.40140560692740124, 0.39071091827484433, 0.38147116953881877, 0.3726983305496507, 0.3680895754012991, 0.3598025448850456, 0.35476922706145814, 0.34759175836849154, 0.3402191032484859, 0.33633154371064883, 0.3338754618713717, 0.32925527780372726, 0.3316020858378495, 0.32320576311349125, 0.31319657449446, 0.2967766312075857, 0.28404009107763906, 0.2686448650416236, 0.2649166365587593, 0.2623066425210806, 0.2569470344233897, 0.26951282389700637, 0.2817920209986071, 0.22151313485788307, 0.17848454135323008, 0.1484831933778036, 0.142170114972701, 0.15931630347821119, 0.17990822363219777, 0.1992979628250325, 0.1911950273309975, 0.1772584848483225, 0.1252331985047838, 0.08672956079661255, 0.07908942049691302, 0.08828012181397842, 0.09147552899239647, 0.080842486445218, 0.0691251390345005, 0.06504879073309766, 0.06252597877185918, 0.06036696511946348, 0.058108235302251496, 0.05489518137867702, 0.05151445771230435, 0.048067699494792615, 0.04540566888113008, 0.04316799961578607, 0.04119386445452422, 0.03927002677976675, 0.03678182440276754, 0.034235744465003166, 0.03145282949581651, 0.028658788991137357, 0.026188993974235568, 0.024763010534467188, 0.024292722947646835, 0.023998419875773325, 0.02308313115946246, 0.021903251640629902, 0.02030430168345783, 0.018157418288248427, 0.0154844756516972, 0.012912374974088942, 0.010557913303479122, 0.008881560075278589, 0.008276712725470594, 0.008696420878208572, 0.009747824404083423, 0.011268307118315958, 0.012441782698283863, 0.013152508540816248, 0.012862405210013675, 0.012491570710902905, 0.011667729213776705]\n",
      "[0.5840241479316859, 0.529134197632855, 0.5130038196705705, 0.49313108601108435, 0.47077579637738054, 0.4543132943205104, 0.44621420315703464, 0.44191409100489504, 0.43847075663914864, 0.4317722849213888, 0.4272283482189614, 0.42283661985299126, 0.4103792435044992, 0.39875524539022716, 0.39056771663511314, 0.3778424401410447, 0.37119565482830486, 0.36118479058616015, 0.3539995499460021, 0.3489782714382293, 0.33663909857722585, 0.3315032448388263, 0.32579885122918933, 0.3219973627505263, 0.3207866253588154, 0.31594871904152433, 0.3173144615530977, 0.31491717188206203, 0.31572164300905625, 0.31563992398037327, 0.3197852601435021, 0.3199369205277897, 0.3221021050593585, 0.32049040416026364, 0.3168099074788656, 0.31453084663322683, 0.3132760004109717, 0.30817733355426735, 0.3131069946201708, 0.30540641288564596, 0.29574136850455707, 0.2783845082182336, 0.2649247968733742, 0.24703467477101104, 0.24326763722293643, 0.24052698608173861, 0.2344238516183464, 0.25011958356901925, 0.2670303402139101, 0.20196527346334514, 0.1538900915605434, 0.12404940597911109, 0.12021870552503269, 0.14178423486719643, 0.16515932737135353, 0.18553745111582495, 0.1777708015504701, 0.1609419716244305, 0.10370888106858998, 0.07201213070139055, 0.06786252622290291, 0.07958746879051186, 0.08373934755704149, 0.07393492396228692, 0.06334935586970841, 0.06010103567758172, 0.0583122499061844, 0.056555838109411345, 0.055083735946270765, 0.052969562038763136, 0.05057335242577495, 0.04813877385265794, 0.04623424189567279, 0.04434201818939734, 0.042626096909350174, 0.040612869022332604, 0.0378055496171159, 0.0348462111538273, 0.031664357545143976, 0.028478014301343547, 0.025669959486679935, 0.0238035802763884, 0.022726525099720937, 0.021992499719386164, 0.020755426513331277, 0.01947061547213166, 0.018046018148443428, 0.016079059375373385, 0.013828215133130702, 0.01155407153427478, 0.009485088569492053, 0.007885840151126531, 0.007086851569763236, 0.007042900138221511, 0.007422950136765589, 0.008251336823920133, 0.008910531875838809, 0.009374912049053974, 0.009186340944538579, 0.00883806519587026, 0.008251168091893635]\n",
      "[0.4682459116304952, 0.4092597345241481, 0.39361138032104304, 0.37141745064572357, 0.3440087437706973, 0.3251507903900673, 0.31917799512534334, 0.31925361672961705, 0.3204720953882585, 0.31671180065938226, 0.31641047084746693, 0.3164268719453317, 0.3043957265145605, 0.29407062478932927, 0.2892275126404233, 0.27770587064887486, 0.27558033609644145, 0.26792973339196474, 0.26509625605066767, 0.26542904619608443, 0.25561196945942494, 0.2556812289384498, 0.25559816955306486, 0.2576597648785705, 0.26386397196506745, 0.26482400514115095, 0.27293013945188127, 0.2759549043497026, 0.28308622118359633, 0.2876670472114173, 0.29693602211353126, 0.3008370521396897, 0.30637672813753464, 0.30672380897747115, 0.3045699708243207, 0.302334684449776, 0.3014776402762645, 0.29625833369178645, 0.30153505657943236, 0.29336523082941446, 0.2834129387873466, 0.26461662317260476, 0.24991624864415973, 0.23003558587240158, 0.22614353503757822, 0.22307636821852905, 0.21665580439214463, 0.23371052231639167, 0.2508015401010173, 0.1837323145482765, 0.13179295055462414, 0.10301295762541977, 0.10404029292778172, 0.1309135353943589, 0.15687624396896951, 0.17675130304339057, 0.16802863713979843, 0.1492099406093722, 0.09193750098955339, 0.06392985124672124, 0.062369767234470956, 0.07360763875354095, 0.07689149573185625, 0.06836570035256419, 0.059690375264591276, 0.05716490398512187, 0.055752151388505526, 0.05415337471678147, 0.05317111746253912, 0.05164187157826135, 0.049794904809209645, 0.04786316492665505, 0.046300902388271434, 0.04459392368561182, 0.04295639164451792, 0.04103589302489371, 0.03814550103322199, 0.03509624777933293, 0.03177572500119598, 0.028414685544514585, 0.02542603558701701, 0.023317484851216132, 0.021900768095555093, 0.02088854595519237, 0.01942145519577199, 0.018056400414710818, 0.016709758701134607, 0.014850545661272956, 0.012878971386254002, 0.010825559213448027, 0.008977686884773843, 0.0075058355678627045, 0.006690790796511096, 0.006518758979182843, 0.006661040427978543, 0.007185462407654322, 0.007616930466919683, 0.007911909469440275, 0.007714039714635473, 0.0073301787728383, 0.006802197377907591]\n",
      "[0.4050289148851131, 0.3494472262690025, 0.33462775793037997, 0.3116669414509049, 0.28231692271559217, 0.26320921827856997, 0.2595001456851641, 0.2631523605376574, 0.2679280734300398, 0.26663484531264037, 0.26899248030174366, 0.2719406946976377, 0.2604893915858713, 0.2510131355660686, 0.24797362295160205, 0.23685894367312998, 0.2372525439934531, 0.23025626315658693, 0.2295357557560261, 0.23207839687920073, 0.22297694769917586, 0.2248686924008864, 0.2269570545636955, 0.23136649025533734, 0.2405531795957563, 0.2439428097485904, 0.25448041249328507, 0.2595437804816993, 0.2688979973455062, 0.27494088982677845, 0.2860406748734425, 0.29064650106703793, 0.2969313183185624, 0.297625982823509, 0.29595204213806975, 0.29352233468818517, 0.2930094883853891, 0.28812844968192275, 0.2931678702351687, 0.28463501670322405, 0.2744620700329267, 0.25494778341546065, 0.23955060112287704, 0.2190578116648361, 0.21548950904981937, 0.21271848333347554, 0.20669154063690293, 0.22326248936533616, 0.23826958925115474, 0.17178011410873784, 0.11939216955831736, 0.09215521319217923, 0.0963279556871795, 0.12569542341920426, 0.15274908698962603, 0.17184749075731598, 0.16215356175796233, 0.14276047994111904, 0.08760196956095764, 0.060635710946349945, 0.059730542275204336, 0.06975883333666895, 0.07241205181177586, 0.06485036359652524, 0.057363508836271115, 0.05513461598645516, 0.05384382269499738, 0.05230015042999059, 0.0515031002259411, 0.05020408320761057, 0.048599895367990066, 0.04690951151335136, 0.04548533368380525, 0.04387188610986417, 0.042255470441337525, 0.04041024003607164, 0.037555119421251205, 0.03455107519352591, 0.031249136765018597, 0.027893651121070125, 0.024903247876063375, 0.0227557487508478, 0.021240632188230833, 0.02013600269261889, 0.018611724183609728, 0.017232195204844675, 0.015918865187969086, 0.014127661752514604, 0.012285851697912709, 0.010361238893638982, 0.008637660646044073, 0.007264097379060912, 0.006478271753603568, 0.006284524393540292, 0.00636113764919244, 0.006785099028370986, 0.0071394670765883754, 0.007366213412822453, 0.007154373128368074, 0.006755970217334286, 0.006242891172068034]\n",
      "[0.3686212930806277, 0.3197860910066233, 0.3060860437046341, 0.2835909419596513, 0.2548018048466455, 0.23712066301800483, 0.23546753825174144, 0.24152704944196887, 0.24845407755674778, 0.2489448450767786, 0.25266606475078174, 0.2571579608186509, 0.24652271728141442, 0.2377541926284539, 0.23550806433902233, 0.22469597772439895, 0.226142114666909, 0.21914493228620122, 0.21914921957828953, 0.22213983709101762, 0.21313803342400456, 0.2152273295872737, 0.2177368485337965, 0.22261060177209382, 0.2324567965538607, 0.23650795903434965, 0.24745683267317903, 0.2529259420948379, 0.26262291818122313, 0.2687994336677848, 0.28023323144586443, 0.2845668212394905, 0.29066218703308433, 0.2911858677429272, 0.28958707110460247, 0.28696418201943613, 0.28667511368036624, 0.28208405123540475, 0.2867681616141134, 0.2780646120907348, 0.26786355456565125, 0.24825293195563303, 0.2327115523649921, 0.21225242367527322, 0.2089504489778365, 0.2065857769846928, 0.20102316121515318, 0.21691633279529401, 0.23030458989461147, 0.1656117973068181, 0.11436038745381714, 0.08823634589806915, 0.093268958649211, 0.12283397558699681, 0.1497797895041603, 0.1682485161165335, 0.15807626644658743, 0.13882784883185242, 0.08557420068858976, 0.058961764069496214, 0.05802738404145873, 0.06715201653566485, 0.06951597939628947, 0.06252242088176489, 0.05565583573538467, 0.05358460552224723, 0.05235971204607901, 0.05087036478233776, 0.05015063626482378, 0.048942113241711126, 0.04744072239526029, 0.045853490369515235, 0.0444904027531563, 0.042922634529657944, 0.041313934064562574, 0.039529876108328026, 0.03674159206476699, 0.033806183343900766, 0.030555958041091166, 0.02725147047191559, 0.0243067645491206, 0.02217656112510982, 0.020635573513863123, 0.019499425716659177, 0.01797400509645359, 0.016602981015596072, 0.015312846437958444, 0.013578035418989621, 0.011818624293207809, 0.00999014226188775, 0.008356744192610214, 0.007064333706200187, 0.006313782157626492, 0.0061212289023685335, 0.006175957132835933, 0.0065586441135955945, 0.0068803065769884, 0.0070781338370115784, 0.006860129467598502, 0.006462571564041299, 0.005959860502202254]\n",
      "[0.3435703049293157, 0.3019115260482023, 0.2893544384051805, 0.267819044896732, 0.2406271595083824, 0.2249798918510301, 0.2250494921520502, 0.2327281190936211, 0.24095707083883527, 0.24273637192536773, 0.2471541893000158, 0.25245730578426784, 0.24257404981425643, 0.2343576097693222, 0.2324238895785142, 0.22184654674654833, 0.22369105822987803, 0.21653312677501582, 0.21673324099516234, 0.21961932565796646, 0.2106077903043246, 0.21246729161429243, 0.21486135054308492, 0.2196091436628302, 0.22936811653182126, 0.23349660003875272, 0.24424834259820968, 0.2496059381794925, 0.2590819313123175, 0.2650111254061268, 0.2763187256633946, 0.28019459685616305, 0.28590764650831835, 0.28614933423152533, 0.28448980094277687, 0.2817263519248784, 0.2815826026923126, 0.277212569153846, 0.28156538128329744, 0.2728037166723556, 0.2626854703040513, 0.24327242184031175, 0.22785845984498374, 0.2076674949439018, 0.20449345695211904, 0.20243519861360218, 0.1971717161268785, 0.212550126457318, 0.2249047882613708, 0.1621830392301812, 0.11237380159663483, 0.0869814965900532, 0.09188031502334307, 0.12087220389928052, 0.1473120858701298, 0.16526372916734716, 0.15487169697298506, 0.13593699956180938, 0.08419316024839642, 0.05782339757552531, 0.05672722654991821, 0.06520276842717965, 0.06740905415449351, 0.060762066136615986, 0.05426531174220626, 0.0522988621597888, 0.0511209286776591, 0.04968085445284004, 0.049004208554943106, 0.04784285287576371, 0.04639935906458627, 0.04486961907641928, 0.043543828346667236, 0.04200633621054027, 0.04040459934843496, 0.038672228460127384, 0.03595150770609543, 0.03308343420911122, 0.02988848009484986, 0.026640815402500975, 0.023747275666157475, 0.021645269074404627, 0.020099153186499127, 0.018950334111302203, 0.01743795348030623, 0.016081220821427794, 0.014810963683033829, 0.013125405251632773, 0.011429984791204092, 0.0096804259553018, 0.00811986523748538, 0.006894810987406653, 0.006176301774057338, 0.005989331814548227, 0.006034005889223508, 0.006393002501536415, 0.006695117439476045, 0.0068763379426275235, 0.006655198191837257, 0.006262780424337408, 0.0057693153183559125]\n",
      "[0.324100685684476, 0.2891239334308429, 0.27759207957665394, 0.2571124683076975, 0.23176839988395415, 0.21818667356067975, 0.21965533607078436, 0.2284791524461619, 0.23755472268991273, 0.2402957552841436, 0.2450934687999522, 0.250868470642519, 0.24160099074903904, 0.2338068796284753, 0.23199084245530988, 0.22158708804667232, 0.22358666543258177, 0.21624991783348615, 0.21647416898988714, 0.21912681426073208, 0.21008894206499945, 0.21164933861618657, 0.21380762643689175, 0.21829728557006708, 0.22778421849023367, 0.2318368666434666, 0.24225983879518626, 0.24738702712744787, 0.2565228074922212, 0.2621376039631657, 0.2732159819829379, 0.27664007743317987, 0.28197732354683197, 0.28194806500332703, 0.28019756814498537, 0.27733598304545093, 0.2773026575564857, 0.27311596158036017, 0.27718123723496235, 0.26841181466684216, 0.25841292104433494, 0.23927949281559072, 0.22407452669369315, 0.2042040337751992, 0.20109511380281048, 0.19926451222983893, 0.19419478770494703, 0.2091638532570777, 0.22076576947669416, 0.15983272857336403, 0.11135578670308223, 0.0864925019713643, 0.09102414895573488, 0.11931182506311538, 0.1451871122209805, 0.16269875000479272, 0.15218802422036914, 0.13358505276762175, 0.08307492497692913, 0.0569185194113583, 0.055651689184157194, 0.0636228842873332, 0.06572296786339814, 0.05932382804927989, 0.053090785324822025, 0.05120390648119779, 0.05006313005904391, 0.04866468240199096, 0.048017048074069785, 0.04688729058305188, 0.04548502036734709, 0.043995707916885306, 0.04269767483382333, 0.04118440460206565, 0.03959044424301758, 0.037902097897745686, 0.03524252618169113, 0.032435409983179654, 0.029292443073454952, 0.02609813782815141, 0.02325188459463252, 0.021178344197438814, 0.01963433795464539, 0.018480340809508857, 0.016984131382373577, 0.015642643458816077, 0.014390099576219503, 0.012747359484065576, 0.011104696739697086, 0.009420954519612274, 0.007920586347609827, 0.006751045556824413, 0.006059797735458406, 0.005878674792690071, 0.005917429942168796, 0.006259649997294701, 0.00654748913382773, 0.0067168542855070845, 0.0064937761136223526, 0.0061072038649084255, 0.005622008524235474]\n",
      "[0.3080928799549733, 0.27913653161180296, 0.2684877766042166, 0.2490288407074356, 0.22551165769488066, 0.2138464511774847, 0.2164467519144769, 0.22611100018383384, 0.23576422235126698, 0.23924113960701385, 0.244251532811684, 0.25032192454193325, 0.24154761832991575, 0.23407998306105762, 0.232297866887615, 0.22202473617290172, 0.22408116899541375, 0.2165818833404041, 0.21677305481012968, 0.21917836677979702, 0.21011410481863788, 0.21139184790207566, 0.2133065345587025, 0.21753115888423616, 0.22671929494687554, 0.2306639340424005, 0.24075409902212003, 0.2456415881048372, 0.2544367600370168, 0.2597510922539026, 0.2705944664752274, 0.2736121087490071, 0.27862070887171475, 0.27835686666662823, 0.27651675929797104, 0.2735867432805186, 0.27364511597058044, 0.2696165186941899, 0.27343365035154743, 0.264677837256246, 0.2548048800992503, 0.23595478542334172, 0.22096910741918976, 0.20140964349386412, 0.1983410880856751, 0.19668968568578507, 0.191756944955972, 0.20638243542861898, 0.21738419889566515, 0.15799789125086283, 0.11067247005855292, 0.08622042765539695, 0.09037194865597735, 0.11799188026287102, 0.14333688771706146, 0.16046931575984827, 0.14988509893612312, 0.13159516316025133, 0.08211706170889056, 0.05615200689892428, 0.05473073526029465, 0.06228936152911101, 0.06430861438700819, 0.05810721477256868, 0.05208308633252786, 0.05026102681037204, 0.049151050543216036, 0.04778731966772421, 0.04716096989418559, 0.04605504700065139, 0.04468525113430589, 0.04322730409216416, 0.041951625875558875, 0.040459061855575976, 0.03887333612559145, 0.03722284610156589, 0.03461739606494561, 0.03186448007253367, 0.02876891494730109, 0.025622872311444892, 0.022818770358772878, 0.020771744192741436, 0.019233034389752646, 0.018077763334908382, 0.016597899811576177, 0.015271268567796481, 0.014034733287528247, 0.012429080571805636, 0.010830789177966304, 0.009202173478183, 0.007751997432623292, 0.0066282432071748075, 0.00595989470133045, 0.005784030464851383, 0.005818815821722998, 0.006148011240430694, 0.00642455992403739, 0.0065846168348754055, 0.006360226975055845, 0.0059792488327802835, 0.0055014190295740485]\n",
      "[0.2945878035683225, 0.2710183791358404, 0.26112306469755964, 0.2426138040244814, 0.2208185609791818, 0.21088163475410276, 0.21440052634056417, 0.22469412617217363, 0.23474962280991515, 0.23879861301246402, 0.24392254148244555, 0.25018271296003874, 0.2418029182423022, 0.23459024202614376, 0.2328002490566611, 0.2226268405723902, 0.22469316357339775, 0.2170530744366893, 0.21719068958672239, 0.21936451750126576, 0.21027704213285212, 0.21130594590083465, 0.2129969728325845, 0.21698049053352517, 0.2258855482848706, 0.22972270793302688, 0.23950737191493576, 0.2441736506624634, 0.25265688755214705, 0.2577022148193371, 0.2683293701431489, 0.2709903953995409, 0.275720261581078, 0.2752588366453891, 0.27333833638234484, 0.2703609854332256, 0.2704980452378741, 0.2666074197641993, 0.2702096700258028, 0.2614764205395753, 0.2517249257077205, 0.23313870002557294, 0.21836047668442998, 0.19908611877807586, 0.19604745495989123, 0.1945422549844506, 0.18971235232054273, 0.20404284223084276, 0.21454730563575447, 0.15648244079463489, 0.11013908785687915, 0.08601848230708006, 0.08982543581022628, 0.11684690138364326, 0.14171538046330653, 0.15851947719133527, 0.14788657489092097, 0.1298826485253849, 0.08127971589811236, 0.055485833205710426, 0.05393046131085715, 0.06114340509022127, 0.06309743544418547, 0.05706132532741323, 0.051210044961801, 0.049442040821878065, 0.04835800981934159, 0.04702328698558715, 0.04641310924402831, 0.04532604376668343, 0.043982874191377336, 0.04255025310351, 0.04129318206598697, 0.039818779545651745, 0.03824140817955804, 0.03662380569000036, 0.03406621748642083, 0.03136141753195216, 0.02830882166709497, 0.025206165292054834, 0.022439551330767055, 0.020416859811344182, 0.018885114375311787, 0.017730984097909568, 0.016266797250562685, 0.01495427051816927, 0.013732282603341505, 0.012158838273474354, 0.010598221795990206, 0.00901603585392062, 0.007607988831259497, 0.006522260351283631, 0.005873184737066034, 0.005701938510806943, 0.005733934189779955, 0.006052648424630192, 0.006319999855126899, 0.0064724473264149, 0.006247179351375039, 0.005871343389192687, 0.005400049954273799]\n",
      "[0.283030633353332, 0.26428245606932527, 0.255030016913605, 0.237392726820203, 0.21719143625786871, 0.20879812169224876, 0.21306684135606363, 0.22383715061905105, 0.23417384143805464, 0.23867254284748357, 0.24384707576618683, 0.25022799100379445, 0.24216481887956337, 0.23515249915853426, 0.23333146128442842, 0.22323458471932006, 0.2252849940347742, 0.21752430138130546, 0.21760098904586087, 0.21956568646615462, 0.21045851136868227, 0.21127264861877548, 0.2127651983926801, 0.2165369237215064, 0.2251851522851529, 0.22892392885704596, 0.23843611643261892, 0.24290533468212222, 0.25111042055484345, 0.2559193725802214, 0.26635393653459194, 0.2687044685691148, 0.27319993904647366, 0.27257329316431517, 0.27058277871554176, 0.26757355611098843, 0.2677787170392151, 0.2640089568747102, 0.2674242277576493, 0.2587169693675576, 0.2490784007996033, 0.23073100085686354, 0.21614241425796762, 0.19712483020655705, 0.1941113598184982, 0.19272777767920132, 0.18797800883156826, 0.20205242152057767, 0.21213748927719905, 0.1551990071374334, 0.10969303662398831, 0.08584437179000398, 0.08934837213019305, 0.11584064846866737, 0.1402863426700107, 0.15680529258886067, 0.14613946007635495, 0.12839417797715486, 0.08054055213548662, 0.05489951263820927, 0.05322941379544569, 0.060149280768642246, 0.06204913148518897, 0.05615357256935462, 0.050447719871473756, 0.04872501724795546, 0.047662851666849866, 0.046352493406025375, 0.045754812578055276, 0.044683014338266276, 0.04336207596762859, 0.04195031617188121, 0.04070903344425686, 0.0392507657943368, 0.03768162374231401, 0.03609284258360657, 0.03357781527554806, 0.030915937891891822, 0.027902335962987704, 0.02483876984813503, 0.02210570478887678, 0.020105287646834797, 0.01858146969844434, 0.01743008410882591, 0.01598069712888629, 0.014681443671180504, 0.013472727165154434, 0.011927351086357561, 0.010398995257091204, 0.008856134260504722, 0.007483740921921199, 0.00642981644512684, 0.005797082485734755, 0.005629903301056491, 0.005659959199173986, 0.005970105479185204, 0.00622988763114236, 0.006376025886513458, 0.006150216142313985, 0.005779043474140271, 0.005313558302767631]\n",
      "[0.27304401952937385, 0.2586209113375962, 0.2499188375346396, 0.23307831332873932, 0.21434111573853912, 0.207322827293701, 0.21220746530171763, 0.22334144573840675, 0.23387326906866857, 0.23872860270753946, 0.24391235118571394, 0.25036669678297474, 0.24255872580354748, 0.23570435126020128, 0.23383874403828878, 0.22380054316144532, 0.22581967905424083, 0.21795566068383068, 0.21796933727521353, 0.21974716134827207, 0.21062331539086626, 0.21125302446288888, 0.21257117255076796, 0.21615895255100515, 0.22457749414525321, 0.22822863683061342, 0.23749993575594672, 0.2417957734357223, 0.24975479198900974, 0.25435711798913063, 0.2646219564963328, 0.26670261089806674, 0.27100127849228156, 0.27023667482617386, 0.2681857288554559, 0.26515616840211975, 0.2654203873366339, 0.26175664440146307, 0.2650083857529525, 0.2563278959602278, 0.2467924471928527, 0.2286590286028495, 0.2142415121638541, 0.195454070035353, 0.19246378661550223, 0.19118268903007635, 0.18649688765984257, 0.2003473945796245, 0.21007507877975687, 0.15409747074427363, 0.10930791925997528, 0.08568466815757993, 0.08892362487428325, 0.11494859786208157, 0.13902024743896707, 0.15529084549750635, 0.14460289806265067, 0.1270909626781284, 0.07988392684087188, 0.05437948503558636, 0.05261163702694151, 0.0592813011231269, 0.06113537127192107, 0.05536012550133536, 0.04977738334453114, 0.048092604363249684, 0.04704888265312657, 0.04575909427581399, 0.0451710964007132, 0.04411179506430654, 0.04280963748794435, 0.041415279260342185, 0.0401875724004932, 0.03874374908293179, 0.03718258916596415, 0.035619310998297425, 0.033142374717036974, 0.03051895941902355, 0.02754087907152298, 0.024512698137914228, 0.021809856858430336, 0.019829915665691752, 0.01831457961161595, 0.017167033810487745, 0.015731544152771004, 0.01444472779487383, 0.013248170682717575, 0.01172737386970867, 0.010226837011416008, 0.008717504470634263, 0.007375496573180429, 0.00634841747686356, 0.005729693088190917, 0.00556612120983551, 0.00559487577014907, 0.005897974361935183, 0.00615153143569659, 0.006292408384455414, 0.006066302440707915, 0.005699354692704774, 0.005239050228172152]\n",
      "[0.26434856158236103, 0.253817098906904, 0.24558825932432973, 0.22947471277336046, 0.21207785561055362, 0.20628484171321257, 0.21167868624452746, 0.22309143651618302, 0.23375617191151626, 0.2388963680274611, 0.24406178837439899, 0.25055621490845403, 0.24295474256911528, 0.2362251236569511, 0.23430699646607472, 0.2243134187588639, 0.22629176149264923, 0.21833887715339387, 0.21828984438593607, 0.2199010044260379, 0.21076291620670592, 0.21123415715923582, 0.2123993491690395, 0.21582773130440394, 0.22404181846077398, 0.22761563338447655, 0.23667435670005998, 0.24081810709686505, 0.24855975881479547, 0.25298147218405453, 0.2630972401950643, 0.26494306206901497, 0.2690763970041686, 0.26819644818116034, 0.2660934680048461, 0.26305228907765976, 0.2633677384743786, 0.2597971257629353, 0.2629050362099133, 0.2542508066681269, 0.2448086746492247, 0.22686631443247215, 0.21260244863983377, 0.1940213105067898, 0.1910535453589886, 0.1898596184859958, 0.1852258520021802, 0.19887939858325268, 0.2083001751331568, 0.15314378706230636, 0.10896992809213077, 0.08553472814802696, 0.08854119962727679, 0.11415244604092513, 0.13789283314114925, 0.1539464815918904, 0.14324418164824415, 0.12594295205206338, 0.0792976809001737, 0.053915520912605513, 0.052064434013067616, 0.05851941957570207, 0.06033437611394858, 0.05466241986345046, 0.049184200888997234, 0.04753104107572084, 0.04650285602280626, 0.04523051239264935, 0.044650051228418836, 0.04360101817348623, 0.04231484455355207, 0.040935145061747315, 0.03971922285533398, 0.03828843856339453, 0.036734941406960354, 0.035194383232211295, 0.03275174539176671, 0.030163007661481403, 0.02721740991952845, 0.024221428930233914, 0.02154600260181035, 0.01958495612810995, 0.018078370614982162, 0.016935436011310902, 0.015512946895414857, 0.014237780859063227, 0.013052381831122341, 0.011553243821391281, 0.010076830199324824, 0.008596278548660146, 0.00728037650569789, 0.006276132821610681, 0.00566950608355989, 0.00550919586658925, 0.0055371556521994336, 0.00583446189807894, 0.006082859364673514, 0.006219348803417116, 0.005993151019960955, 0.00563003295456854, 0.005174349608002727]\n",
      "[0.256728093418144, 0.2497094141711332, 0.24188939523839653, 0.22643925130405826, 0.21026807697016842, 0.20556884631031963, 0.2113864987884509, 0.22301353351886263, 0.23376576586437503, 0.23913484380352582, 0.24426357543504734, 0.25077432296257895, 0.24334043696722701, 0.23670927023115107, 0.23473417810780084, 0.22477413015226902, 0.22670573252881113, 0.21867605012579092, 0.21856567098208673, 0.22002797800393328, 0.2108775763621435, 0.21121224940996117, 0.21224306965456333, 0.2155332111184947, 0.22356534951712212, 0.2270710236203897, 0.23594190423563263, 0.23995232337313857, 0.24750168503592396, 0.25176519934216546, 0.2617500203257374, 0.26339112720803864, 0.26738524107799155, 0.26640874221627514, 0.26426094118668314, 0.2612147353011918, 0.2615745662589694, 0.25808589532483467, 0.2610666578130583, 0.2524375715742831, 0.2430794857358452, 0.22530770392009988, 0.21118168256590356, 0.192785896071753, 0.1898406165805491, 0.1887214912225183, 0.18413064776495763, 0.19761000624328676, 0.20676550398967647, 0.1523126065302234, 0.10867037230895908, 0.08539285471351529, 0.0881943388895443, 0.11343783054179592, 0.13688412362753952, 0.1527476191728338, 0.14203670322456544, 0.12492614913973922, 0.07877195786498864, 0.0534995321145205, 0.05157744952400546, 0.05784748628056119, 0.059628705499185274, 0.0540455704791942, 0.048656212890940104, 0.04702933002092715, 0.0460141603310697, 0.044756698202031944, 0.04418207332856313, 0.043141537395557455, 0.04186904906051104, 0.04050179103549059, 0.03929618378220158, 0.03787722855157151, 0.03633103366169957, 0.03481087890004314, 0.0323992853452556, 0.029841992428421837, 0.026926217421336145, 0.023959664675588462, 0.021309271876815195, 0.019365705156538692, 0.017867981190876302, 0.01673015836479572, 0.015319826430937652, 0.014055573563004853, 0.012880462092787866, 0.011400496263252636, 0.009945154805241432, 0.00848945906880665, 0.0071961151906624705, 0.00621146236956356, 0.005615391981575407, 0.005458044590214777, 0.0054856239202921995, 0.005778154928167066, 0.006022313130697305, 0.006155124663958605, 0.005928998999368539, 0.005569369943841883, 0.005117818490607787]\n",
      "[0.2500111708951069, 0.24617344196445964, 0.2387082643976759, 0.2238640553559362, 0.20881381973654392, 0.2050935711076116, 0.21126616461438266, 0.2230581520844467, 0.23386445994969118, 0.23941837029139654, 0.2444983667400611, 0.2510083060454553, 0.2437108359405927, 0.2371571360343862, 0.235122849488202, 0.22518747855430568, 0.22706872079225865, 0.21897226188303687, 0.21880243535476898, 0.22013143825268291, 0.2109702074527269, 0.2111867746812827, 0.21209916190491748, 0.21526914061002583, 0.22313905164013026, 0.2265846607074926, 0.23528914660747544, 0.2391824309551326, 0.24656124834553447, 0.2506858043448608, 0.26055537770969694, 0.2620175702791182, 0.26589419861040453, 0.2648367966476848, 0.2626502745240137, 0.2596040484730405, 0.2600023468641251, 0.25658587481453354, 0.2594536807652666, 0.2508483382517369, 0.2415658157236354, 0.22394653035031986, 0.2099442681741802, 0.19171551190778832, 0.1887930077708682, 0.18773853647977348, 0.18318354322663646, 0.1965080928025751, 0.20543294967066353, 0.15158414095293032, 0.1084031194758773, 0.08525828646104956, 0.08787803282689582, 0.11279320937680949, 0.13597753366668372, 0.1516738447474122, 0.14095859044969836, 0.12402102840442716, 0.07829860038504484, 0.05312492178900014, 0.05114216025919997, 0.057252251990214845, 0.05900414863559411, 0.05349748387363061, 0.04818375389382399, 0.04657855884252011, 0.04557430514806332, 0.044329590306915065, 0.04375944542671317, 0.04272595827727647, 0.04146526049755316, 0.040108612252577926, 0.038912090974013804, 0.03750391594237856, 0.03596465767441312, 0.0344629272666696, 0.03207961412412381, 0.029550944774049386, 0.026662647756358366, 0.02372312682165368, 0.021095691669651, 0.01916836126600281, 0.0176794843166872, 0.016547089232331638, 0.015148153928346512, 0.013894119318396242, 0.012728489319284254, 0.011265589066383584, 0.00982874545251145, 0.008394664678729048, 0.007120956437134522, 0.006153231667737663, 0.005566429409879001, 0.005411827424372125, 0.005439358552704787, 0.0057279668335213875, 0.005968631949940921, 0.006098373830054034, 0.005872435924823639, 0.005515988210585796, 0.005068152036244232]\n",
      "[0.24405965415906805, 0.24311137631153293, 0.23595560221012568, 0.22166558291877525, 0.2076414007989725, 0.20479997676844983, 0.21127176029495598, 0.22319061699697684, 0.23402631599139886, 0.2397301520823027, 0.24475366562342676, 0.25125050135200844, 0.24406419607177499, 0.23757115452649863, 0.23547694118376367, 0.22555911213408375, 0.22738797075239348, 0.21923311922941455, 0.21900600832734712, 0.2202151459344732, 0.21104428314975499, 0.21115828297385542, 0.21196587989031654, 0.21503108864191098, 0.22275602602040245, 0.22614849441805987, 0.23470512027493806, 0.2384952787015563, 0.24572231998567667, 0.249724443518595, 0.2594923532323263, 0.2607977286895129, 0.2645750696434416, 0.2634497138023907, 0.2612296318857563, 0.25818726537343617, 0.2586188564903451, 0.2552661465801578, 0.2580330874117439, 0.24945002323412058, 0.24023538599057168, 0.2227526853468494, 0.20886177203949888, 0.19078404406426488, 0.18788468128125166, 0.1868865069895781, 0.18236180342784486, 0.19554806753368584, 0.20427136414890987, 0.1509425705506516, 0.1081634711600264, 0.08513066674375153, 0.08758831133615981, 0.11220911668544123, 0.13515926808490797, 0.15070808938370675, 0.1399917369778155, 0.12321161560918471, 0.07787076554533975, 0.05278622557226629, 0.050751450719477884, 0.05672274936417802, 0.058448999656148366, 0.05300820606210717, 0.04775885172774083, 0.046171504354296615, 0.045176371736846105, 0.04394261716095697, 0.04337585403589204, 0.04234823216653121, 0.041097707419451, 0.03975019323449594, 0.038561715306524635, 0.03716342673190644, 0.03563073539718616, 0.03414573412131844, 0.031788295141385946, 0.029285808956741582, 0.026422918712285172, 0.02350828996947863, 0.020902025655028328, 0.018989815488393888, 0.01750968225962109, 0.016382900638365148, 0.014994629299657272, 0.013750186156909908, 0.01259333225145882, 0.011145695883457006, 0.009725186653354785, 0.008309994253561152, 0.007053478011317512, 0.006100497855555761, 0.005521907446947837, 0.005369842120001293, 0.005397580453833069, 0.0056829802469704664, 0.005920800163542712, 0.006047965997242854, 0.005822306731913801, 0.005468773093122232, 0.005024284737040094]\n",
      "[0.2387609335472397, 0.2404452814088712, 0.2335604738459957, 0.21977821428913516, 0.2066944400641872, 0.20464445605389384, 0.21136993659069203, 0.22338608876711097, 0.23423295573294756, 0.2400587542929161, 0.2450211011370771, 0.2514959436091391, 0.2444003074022468, 0.23795435412222055, 0.23580045374475397, 0.22589445500872746, 0.22766998882830095, 0.21946379359835716, 0.21918163042733882, 0.22028261027679277, 0.21110301882290977, 0.21112758078749377, 0.21184210145509286, 0.2148156533862755, 0.22241061436012585, 0.22575597472582576, 0.23418075095073307, 0.23787986650625453, 0.24497137843369163, 0.2488652851979403, 0.25854324432185183, 0.2597107584596083, 0.26340399738437487, 0.2622215576256836, 0.2599723497951819, 0.2569366710848619, 0.25739713180892765, 0.2541008296499372, 0.2567773041434646, 0.2482150633679579, 0.23906146716966234, 0.22170141749020564, 0.20791089203412763, 0.18997022000930358, 0.18709434272405506, 0.18614550269675595, 0.1816466611476254, 0.19470885004397306, 0.20325513204995124, 0.150374969983665, 0.10794765790468258, 0.08500965814687625, 0.08732197781021826, 0.11167767907179095, 0.13441779660716283, 0.14983607146029598, 0.13912107446828406, 0.12248467881166582, 0.0774827034215415, 0.052478846748105316, 0.05039937589716723, 0.05624984060763637, 0.05795352029214004, 0.05256953474253306, 0.04737500209125766, 0.045802202869813305, 0.04481466131351209, 0.043590386048592396, 0.04302613020719432, 0.042003379290292374, 0.04076170158820471, 0.03942205700448117, 0.038240758795309755, 0.03685153121919178, 0.03532506885204824, 0.033855331615557184, 0.031521647712180294, 0.029043216554029482, 0.026203892467972344, 0.023312293286084, 0.020725609276352454, 0.018827514122221015, 0.017355960708460332, 0.0162348859457725, 0.014856621920708987, 0.013621164024068405, 0.01247246731940464, 0.011038545394221506, 0.009632526763088274, 0.008233937750648802, 0.0069925671322398795, 0.006052492308978954, 0.005481219039490608, 0.0053315370722917844, 0.005359705516423484, 0.005642475616016406, 0.005877977800292721, 0.006002995877834252, 0.005777699682655181, 0.005426834849631054, 0.004985364803247551]\n",
      "[0.23402235881339167, 0.23811234908928344, 0.23146584480325227, 0.21814961150847895, 0.2059291180129777, 0.20459420655267935, 0.21153610581193666, 0.22362644209415145, 0.23447096671799758, 0.24039624892829678, 0.24529484655835307, 0.2517414400516886, 0.24471970038016197, 0.2383098362815006, 0.23609713888626754, 0.22619834588251575, 0.2279203484272715, 0.21966875900598926, 0.21933378070406362, 0.22033679153216443, 0.2111492152442637, 0.21109548809946121, 0.21172700630143187, 0.21462006660151414, 0.22209817812203225, 0.22540159574138507, 0.23370839405058758, 0.23732690233136808, 0.24429696937709422, 0.2480948646283666, 0.2576930363345886, 0.25873902448441616, 0.26236092012192086, 0.26113049703934577, 0.2588558832083969, 0.2558291159508387, 0.25631457860683077, 0.2530682922548534, 0.25566326074667184, 0.24712044869323002, 0.23802176915623002, 0.22077214917746418, 0.2070723797971237, 0.18925647473832807, 0.18640439138432735, 0.1854990546300123, 0.18102249269251972, 0.19397290896886032, 0.20236300147388794, 0.14987076341837274, 0.10775261344166122, 0.08489500036414235, 0.08707635953334697, 0.11119236576469267, 0.13374339477019076, 0.1490457656747108, 0.13833398436914887, 0.12182919970055925, 0.07712952412462122, 0.052198939010387066, 0.05008092340503486, 0.05582588642271838, 0.05750960338736022, 0.0521746339562813, 0.047026775136308874, 0.045465740725208974, 0.04448449755760444, 0.043268422851644686, 0.042705971896927306, 0.041687271566818285, 0.04045329166368211, 0.039120476108642874, 0.0379456023879166, 0.03656473706696564, 0.03504415509914952, 0.033588411724482146, 0.03127663880571903, 0.028820374976337063, 0.026002976306698497, 0.02313275237120044, 0.020564244327351194, 0.018679356113695568, 0.017216171749616253, 0.01610082292498281, 0.014731946896072635, 0.013504950331287442, 0.012363820773641867, 0.010942256374979278, 0.009549176004841033, 0.008165260333304218, 0.006937295731443713, 0.006008598338050408, 0.005443889294557107, 0.005296452945715055, 0.005325201314353675, 0.005605862876824607, 0.005839484700728935, 0.005962712196013848, 0.005737818444247735, 0.005389416242879595, 0.004950682408371269]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for filter_index, filter in enumerate(filter_dict):\n",
    "\n",
    "    lowdiff_ind, highdiff_ind = lowdiff[filter_index], highdiff[filter_index]\n",
    "\n",
    "    plot_diff_distr(filter, lowdiff_ind, highdiff_ind, args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
